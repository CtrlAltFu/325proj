{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "##import pandas_profiling\n",
    "\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras import layers\n",
    "import math\n",
    "import mlflow.sklearn\n",
    "from azureml.core import Workspace\n",
    "import urllib.request\n",
    "import json\n",
    "import os\n",
    "import ssl\n",
    "\n",
    "\n",
    "#Easier way of standardizing the data since we're working with larger components\n",
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn import model_selection, preprocessing\n",
    "from sklearn import metrics\n",
    "\n",
    "\n",
    "#All the azure stuff\n",
    "import mlflow\n",
    "from mlflow.azureml import deploy\n",
    "\n",
    "from azureml.core import Workspace\n",
    "from mlflow.tracking.artifact_utils import _download_artifact_from_uri\n",
    "from azureml.core.webservice import AciWebservice, Webservice\n",
    "import azure.core\n",
    "\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['.ipynb_checkpoints',\n",
       " 'BTC-Time-Series-Model.ipynb',\n",
       " 'btc-usdt.csv',\n",
       " 'config.json',\n",
       " 'finalProject.ipynb',\n",
       " 'FinalProjectV2.ipynb',\n",
       " 'lstm.ipynb',\n",
       " 'Main.ipynb',\n",
       " 'newTest - Copy.ipynb',\n",
       " 'newTest.ipynb',\n",
       " 'origRNN.ipynb',\n",
       " 'starter.ipynb',\n",
       " 'Test.ipynb']"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.listdir('./')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Open Time</th>\n",
       "      <th>Open</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Close</th>\n",
       "      <th>Volume</th>\n",
       "      <th>Close Time</th>\n",
       "      <th>Quote Asset Volume</th>\n",
       "      <th>Number of Trades</th>\n",
       "      <th>TB Base Volume</th>\n",
       "      <th>TB Quote Volume</th>\n",
       "      <th>Ignore</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2019-07-30 00:00:00.000000000</td>\n",
       "      <td>9509.07</td>\n",
       "      <td>9535.00</td>\n",
       "      <td>9503.07</td>\n",
       "      <td>9517.75</td>\n",
       "      <td>381.293856</td>\n",
       "      <td>2019-07-30 00:29:59.999000064</td>\n",
       "      <td>3.631211e+06</td>\n",
       "      <td>3492</td>\n",
       "      <td>216.528742</td>\n",
       "      <td>2.062189e+06</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2019-07-30 00:30:00.000000000</td>\n",
       "      <td>9517.03</td>\n",
       "      <td>9539.00</td>\n",
       "      <td>9507.00</td>\n",
       "      <td>9532.58</td>\n",
       "      <td>258.514869</td>\n",
       "      <td>2019-07-30 00:59:59.999000064</td>\n",
       "      <td>2.462134e+06</td>\n",
       "      <td>3133</td>\n",
       "      <td>141.887550</td>\n",
       "      <td>1.351182e+06</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2019-07-30 01:00:00.000000000</td>\n",
       "      <td>9533.59</td>\n",
       "      <td>9534.00</td>\n",
       "      <td>9500.00</td>\n",
       "      <td>9500.25</td>\n",
       "      <td>275.797270</td>\n",
       "      <td>2019-07-30 01:29:59.999000064</td>\n",
       "      <td>2.624322e+06</td>\n",
       "      <td>3583</td>\n",
       "      <td>114.238457</td>\n",
       "      <td>1.087402e+06</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2019-07-30 01:30:00.000000000</td>\n",
       "      <td>9500.25</td>\n",
       "      <td>9514.46</td>\n",
       "      <td>9460.71</td>\n",
       "      <td>9465.25</td>\n",
       "      <td>485.218470</td>\n",
       "      <td>2019-07-30 01:59:59.999000064</td>\n",
       "      <td>4.604004e+06</td>\n",
       "      <td>5330</td>\n",
       "      <td>225.681291</td>\n",
       "      <td>2.141459e+06</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2019-07-30 02:00:00.000000000</td>\n",
       "      <td>9465.25</td>\n",
       "      <td>9488.94</td>\n",
       "      <td>9430.01</td>\n",
       "      <td>9460.42</td>\n",
       "      <td>498.669626</td>\n",
       "      <td>2019-07-30 02:29:59.999000064</td>\n",
       "      <td>4.717269e+06</td>\n",
       "      <td>6197</td>\n",
       "      <td>228.535910</td>\n",
       "      <td>2.162163e+06</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       Open Time     Open     High      Low    Close  \\\n",
       "0  2019-07-30 00:00:00.000000000  9509.07  9535.00  9503.07  9517.75   \n",
       "1  2019-07-30 00:30:00.000000000  9517.03  9539.00  9507.00  9532.58   \n",
       "2  2019-07-30 01:00:00.000000000  9533.59  9534.00  9500.00  9500.25   \n",
       "3  2019-07-30 01:30:00.000000000  9500.25  9514.46  9460.71  9465.25   \n",
       "4  2019-07-30 02:00:00.000000000  9465.25  9488.94  9430.01  9460.42   \n",
       "\n",
       "       Volume                     Close Time  Quote Asset Volume  \\\n",
       "0  381.293856  2019-07-30 00:29:59.999000064        3.631211e+06   \n",
       "1  258.514869  2019-07-30 00:59:59.999000064        2.462134e+06   \n",
       "2  275.797270  2019-07-30 01:29:59.999000064        2.624322e+06   \n",
       "3  485.218470  2019-07-30 01:59:59.999000064        4.604004e+06   \n",
       "4  498.669626  2019-07-30 02:29:59.999000064        4.717269e+06   \n",
       "\n",
       "   Number of Trades  TB Base Volume  TB Quote Volume  Ignore  \n",
       "0              3492      216.528742     2.062189e+06       0  \n",
       "1              3133      141.887550     1.351182e+06       0  \n",
       "2              3583      114.238457     1.087402e+06       0  \n",
       "3              5330      225.681291     2.141459e+06       0  \n",
       "4              6197      228.535910     2.162163e+06       0  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "baseDataFrame = pd.read_csv(\"btc-usdt.csv\")\n",
    "baseDataFrame.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pandas.core.series.Series"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(baseDataFrame[\"Open Time\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Open Time              object\n",
       "Open                  float64\n",
       "High                  float64\n",
       "Low                   float64\n",
       "Close                 float64\n",
       "Volume                float64\n",
       "Close Time             object\n",
       "Quote Asset Volume    float64\n",
       "Number of Trades        int64\n",
       "TB Base Volume        float64\n",
       "TB Quote Volume       float64\n",
       "Ignore                  int64\n",
       "dtype: object"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Change the open tim to a simpler open date\n",
    "newDF = pd.DataFrame(baseDataFrame)\n",
    "newDF[\"Open Time\"] = pd.to_datetime(newDF[\"Open Time\"])\n",
    "newDF[\"Open Time\"] = newDF[\"Open Time\"].dt.date\n",
    "baseDataFrame.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Open Time             datetime64[ns]\n",
       "Open                         float64\n",
       "High                         float64\n",
       "Low                          float64\n",
       "Close                        float64\n",
       "Volume                       float64\n",
       "Close Time                    object\n",
       "Quote Asset Volume           float64\n",
       "Number of Trades               int64\n",
       "TB Base Volume               float64\n",
       "TB Quote Volume              float64\n",
       "Ignore                         int64\n",
       "dtype: object"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "newDF[\"Open Time\"] = pd.to_datetime(newDF[\"Open Time\"])\n",
    "baseDataFrame.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Open Time</th>\n",
       "      <th>Open</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Close</th>\n",
       "      <th>Volume</th>\n",
       "      <th>Close Time</th>\n",
       "      <th>Quote Asset Volume</th>\n",
       "      <th>Number of Trades</th>\n",
       "      <th>TB Base Volume</th>\n",
       "      <th>TB Quote Volume</th>\n",
       "      <th>Ignore</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2019-07-30</td>\n",
       "      <td>9509.07</td>\n",
       "      <td>9535.00</td>\n",
       "      <td>9503.07</td>\n",
       "      <td>9517.75</td>\n",
       "      <td>381.293856</td>\n",
       "      <td>2019-07-30 00:29:59.999000064</td>\n",
       "      <td>3.631211e+06</td>\n",
       "      <td>3492</td>\n",
       "      <td>216.528742</td>\n",
       "      <td>2.062189e+06</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2019-07-30</td>\n",
       "      <td>9517.03</td>\n",
       "      <td>9539.00</td>\n",
       "      <td>9507.00</td>\n",
       "      <td>9532.58</td>\n",
       "      <td>258.514869</td>\n",
       "      <td>2019-07-30 00:59:59.999000064</td>\n",
       "      <td>2.462134e+06</td>\n",
       "      <td>3133</td>\n",
       "      <td>141.887550</td>\n",
       "      <td>1.351182e+06</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2019-07-30</td>\n",
       "      <td>9533.59</td>\n",
       "      <td>9534.00</td>\n",
       "      <td>9500.00</td>\n",
       "      <td>9500.25</td>\n",
       "      <td>275.797270</td>\n",
       "      <td>2019-07-30 01:29:59.999000064</td>\n",
       "      <td>2.624322e+06</td>\n",
       "      <td>3583</td>\n",
       "      <td>114.238457</td>\n",
       "      <td>1.087402e+06</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2019-07-30</td>\n",
       "      <td>9500.25</td>\n",
       "      <td>9514.46</td>\n",
       "      <td>9460.71</td>\n",
       "      <td>9465.25</td>\n",
       "      <td>485.218470</td>\n",
       "      <td>2019-07-30 01:59:59.999000064</td>\n",
       "      <td>4.604004e+06</td>\n",
       "      <td>5330</td>\n",
       "      <td>225.681291</td>\n",
       "      <td>2.141459e+06</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2019-07-30</td>\n",
       "      <td>9465.25</td>\n",
       "      <td>9488.94</td>\n",
       "      <td>9430.01</td>\n",
       "      <td>9460.42</td>\n",
       "      <td>498.669626</td>\n",
       "      <td>2019-07-30 02:29:59.999000064</td>\n",
       "      <td>4.717269e+06</td>\n",
       "      <td>6197</td>\n",
       "      <td>228.535910</td>\n",
       "      <td>2.162163e+06</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Open Time     Open     High      Low    Close      Volume  \\\n",
       "0 2019-07-30  9509.07  9535.00  9503.07  9517.75  381.293856   \n",
       "1 2019-07-30  9517.03  9539.00  9507.00  9532.58  258.514869   \n",
       "2 2019-07-30  9533.59  9534.00  9500.00  9500.25  275.797270   \n",
       "3 2019-07-30  9500.25  9514.46  9460.71  9465.25  485.218470   \n",
       "4 2019-07-30  9465.25  9488.94  9430.01  9460.42  498.669626   \n",
       "\n",
       "                      Close Time  Quote Asset Volume  Number of Trades  \\\n",
       "0  2019-07-30 00:29:59.999000064        3.631211e+06              3492   \n",
       "1  2019-07-30 00:59:59.999000064        2.462134e+06              3133   \n",
       "2  2019-07-30 01:29:59.999000064        2.624322e+06              3583   \n",
       "3  2019-07-30 01:59:59.999000064        4.604004e+06              5330   \n",
       "4  2019-07-30 02:29:59.999000064        4.717269e+06              6197   \n",
       "\n",
       "   TB Base Volume  TB Quote Volume  Ignore  \n",
       "0      216.528742     2.062189e+06       0  \n",
       "1      141.887550     1.351182e+06       0  \n",
       "2      114.238457     1.087402e+06       0  \n",
       "3      225.681291     2.141459e+06       0  \n",
       "4      228.535910     2.162163e+06       0  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "newDF.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Open Time</th>\n",
       "      <th>Open</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Close</th>\n",
       "      <th>Volume</th>\n",
       "      <th>Quote Asset Volume</th>\n",
       "      <th>Number of Trades</th>\n",
       "      <th>TB Base Volume</th>\n",
       "      <th>TB Quote Volume</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2019-07-30</td>\n",
       "      <td>9509.07</td>\n",
       "      <td>9535.00</td>\n",
       "      <td>9503.07</td>\n",
       "      <td>9517.75</td>\n",
       "      <td>381.293856</td>\n",
       "      <td>3.631211e+06</td>\n",
       "      <td>3492</td>\n",
       "      <td>216.528742</td>\n",
       "      <td>2.062189e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2019-07-30</td>\n",
       "      <td>9517.03</td>\n",
       "      <td>9539.00</td>\n",
       "      <td>9507.00</td>\n",
       "      <td>9532.58</td>\n",
       "      <td>258.514869</td>\n",
       "      <td>2.462134e+06</td>\n",
       "      <td>3133</td>\n",
       "      <td>141.887550</td>\n",
       "      <td>1.351182e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2019-07-30</td>\n",
       "      <td>9533.59</td>\n",
       "      <td>9534.00</td>\n",
       "      <td>9500.00</td>\n",
       "      <td>9500.25</td>\n",
       "      <td>275.797270</td>\n",
       "      <td>2.624322e+06</td>\n",
       "      <td>3583</td>\n",
       "      <td>114.238457</td>\n",
       "      <td>1.087402e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2019-07-30</td>\n",
       "      <td>9500.25</td>\n",
       "      <td>9514.46</td>\n",
       "      <td>9460.71</td>\n",
       "      <td>9465.25</td>\n",
       "      <td>485.218470</td>\n",
       "      <td>4.604004e+06</td>\n",
       "      <td>5330</td>\n",
       "      <td>225.681291</td>\n",
       "      <td>2.141459e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2019-07-30</td>\n",
       "      <td>9465.25</td>\n",
       "      <td>9488.94</td>\n",
       "      <td>9430.01</td>\n",
       "      <td>9460.42</td>\n",
       "      <td>498.669626</td>\n",
       "      <td>4.717269e+06</td>\n",
       "      <td>6197</td>\n",
       "      <td>228.535910</td>\n",
       "      <td>2.162163e+06</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Open Time     Open     High      Low    Close      Volume  \\\n",
       "0 2019-07-30  9509.07  9535.00  9503.07  9517.75  381.293856   \n",
       "1 2019-07-30  9517.03  9539.00  9507.00  9532.58  258.514869   \n",
       "2 2019-07-30  9533.59  9534.00  9500.00  9500.25  275.797270   \n",
       "3 2019-07-30  9500.25  9514.46  9460.71  9465.25  485.218470   \n",
       "4 2019-07-30  9465.25  9488.94  9430.01  9460.42  498.669626   \n",
       "\n",
       "   Quote Asset Volume  Number of Trades  TB Base Volume  TB Quote Volume  \n",
       "0        3.631211e+06              3492      216.528742     2.062189e+06  \n",
       "1        2.462134e+06              3133      141.887550     1.351182e+06  \n",
       "2        2.624322e+06              3583      114.238457     1.087402e+06  \n",
       "3        4.604004e+06              5330      225.681291     2.141459e+06  \n",
       "4        4.717269e+06              6197      228.535910     2.162163e+06  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "newDF = newDF.drop([\"Close Time\", \"Ignore\"], axis = 1)\n",
    "newDF.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#finding out what the gain is on each day\n",
    "newDF[\"yesterdayGain\"] = newDF[\"Close\"].shift(1)\n",
    "newDF[\"tomorrowGain\"] =  newDF[\"Close\"].shift(-1) - newDF[\"Close\"]\n",
    "#Needs this to account for the afterhours markets\n",
    "newDF[\"tomorrowOpen\"] = newDF[\"Open\"].shift(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Open Time</th>\n",
       "      <th>Open</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Close</th>\n",
       "      <th>Volume</th>\n",
       "      <th>Quote Asset Volume</th>\n",
       "      <th>Number of Trades</th>\n",
       "      <th>TB Base Volume</th>\n",
       "      <th>TB Quote Volume</th>\n",
       "      <th>yesterdayGain</th>\n",
       "      <th>tomorrowGain</th>\n",
       "      <th>tomorrowOpen</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2019-07-30</td>\n",
       "      <td>9509.07</td>\n",
       "      <td>9535.00</td>\n",
       "      <td>9503.07</td>\n",
       "      <td>9517.75</td>\n",
       "      <td>381.293856</td>\n",
       "      <td>3.631211e+06</td>\n",
       "      <td>3492</td>\n",
       "      <td>216.528742</td>\n",
       "      <td>2.062189e+06</td>\n",
       "      <td>NaN</td>\n",
       "      <td>14.83</td>\n",
       "      <td>9517.03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2019-07-30</td>\n",
       "      <td>9517.03</td>\n",
       "      <td>9539.00</td>\n",
       "      <td>9507.00</td>\n",
       "      <td>9532.58</td>\n",
       "      <td>258.514869</td>\n",
       "      <td>2.462134e+06</td>\n",
       "      <td>3133</td>\n",
       "      <td>141.887550</td>\n",
       "      <td>1.351182e+06</td>\n",
       "      <td>9517.75</td>\n",
       "      <td>-32.33</td>\n",
       "      <td>9533.59</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2019-07-30</td>\n",
       "      <td>9533.59</td>\n",
       "      <td>9534.00</td>\n",
       "      <td>9500.00</td>\n",
       "      <td>9500.25</td>\n",
       "      <td>275.797270</td>\n",
       "      <td>2.624322e+06</td>\n",
       "      <td>3583</td>\n",
       "      <td>114.238457</td>\n",
       "      <td>1.087402e+06</td>\n",
       "      <td>9532.58</td>\n",
       "      <td>-35.00</td>\n",
       "      <td>9500.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2019-07-30</td>\n",
       "      <td>9500.25</td>\n",
       "      <td>9514.46</td>\n",
       "      <td>9460.71</td>\n",
       "      <td>9465.25</td>\n",
       "      <td>485.218470</td>\n",
       "      <td>4.604004e+06</td>\n",
       "      <td>5330</td>\n",
       "      <td>225.681291</td>\n",
       "      <td>2.141459e+06</td>\n",
       "      <td>9500.25</td>\n",
       "      <td>-4.83</td>\n",
       "      <td>9465.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2019-07-30</td>\n",
       "      <td>9465.25</td>\n",
       "      <td>9488.94</td>\n",
       "      <td>9430.01</td>\n",
       "      <td>9460.42</td>\n",
       "      <td>498.669626</td>\n",
       "      <td>4.717269e+06</td>\n",
       "      <td>6197</td>\n",
       "      <td>228.535910</td>\n",
       "      <td>2.162163e+06</td>\n",
       "      <td>9465.25</td>\n",
       "      <td>-34.87</td>\n",
       "      <td>9461.73</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Open Time     Open     High      Low    Close      Volume  \\\n",
       "0 2019-07-30  9509.07  9535.00  9503.07  9517.75  381.293856   \n",
       "1 2019-07-30  9517.03  9539.00  9507.00  9532.58  258.514869   \n",
       "2 2019-07-30  9533.59  9534.00  9500.00  9500.25  275.797270   \n",
       "3 2019-07-30  9500.25  9514.46  9460.71  9465.25  485.218470   \n",
       "4 2019-07-30  9465.25  9488.94  9430.01  9460.42  498.669626   \n",
       "\n",
       "   Quote Asset Volume  Number of Trades  TB Base Volume  TB Quote Volume  \\\n",
       "0        3.631211e+06              3492      216.528742     2.062189e+06   \n",
       "1        2.462134e+06              3133      141.887550     1.351182e+06   \n",
       "2        2.624322e+06              3583      114.238457     1.087402e+06   \n",
       "3        4.604004e+06              5330      225.681291     2.141459e+06   \n",
       "4        4.717269e+06              6197      228.535910     2.162163e+06   \n",
       "\n",
       "   yesterdayGain  tomorrowGain  tomorrowOpen  \n",
       "0            NaN         14.83       9517.03  \n",
       "1        9517.75        -32.33       9533.59  \n",
       "2        9532.58        -35.00       9500.25  \n",
       "3        9500.25         -4.83       9465.25  \n",
       "4        9465.25        -34.87       9461.73  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "newDF.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Open Time</th>\n",
       "      <th>Open</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Close</th>\n",
       "      <th>Volume</th>\n",
       "      <th>Quote Asset Volume</th>\n",
       "      <th>Number of Trades</th>\n",
       "      <th>TB Base Volume</th>\n",
       "      <th>TB Quote Volume</th>\n",
       "      <th>yesterdayGain</th>\n",
       "      <th>tomorrowGain</th>\n",
       "      <th>tomorrowOpen</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2019-07-30</td>\n",
       "      <td>9517.03</td>\n",
       "      <td>9539.00</td>\n",
       "      <td>9507.00</td>\n",
       "      <td>9532.58</td>\n",
       "      <td>258.514869</td>\n",
       "      <td>2.462134e+06</td>\n",
       "      <td>3133</td>\n",
       "      <td>141.887550</td>\n",
       "      <td>1.351182e+06</td>\n",
       "      <td>9517.75</td>\n",
       "      <td>-32.33</td>\n",
       "      <td>9533.59</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2019-07-30</td>\n",
       "      <td>9533.59</td>\n",
       "      <td>9534.00</td>\n",
       "      <td>9500.00</td>\n",
       "      <td>9500.25</td>\n",
       "      <td>275.797270</td>\n",
       "      <td>2.624322e+06</td>\n",
       "      <td>3583</td>\n",
       "      <td>114.238457</td>\n",
       "      <td>1.087402e+06</td>\n",
       "      <td>9532.58</td>\n",
       "      <td>-35.00</td>\n",
       "      <td>9500.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2019-07-30</td>\n",
       "      <td>9500.25</td>\n",
       "      <td>9514.46</td>\n",
       "      <td>9460.71</td>\n",
       "      <td>9465.25</td>\n",
       "      <td>485.218470</td>\n",
       "      <td>4.604004e+06</td>\n",
       "      <td>5330</td>\n",
       "      <td>225.681291</td>\n",
       "      <td>2.141459e+06</td>\n",
       "      <td>9500.25</td>\n",
       "      <td>-4.83</td>\n",
       "      <td>9465.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2019-07-30</td>\n",
       "      <td>9465.25</td>\n",
       "      <td>9488.94</td>\n",
       "      <td>9430.01</td>\n",
       "      <td>9460.42</td>\n",
       "      <td>498.669626</td>\n",
       "      <td>4.717269e+06</td>\n",
       "      <td>6197</td>\n",
       "      <td>228.535910</td>\n",
       "      <td>2.162163e+06</td>\n",
       "      <td>9465.25</td>\n",
       "      <td>-34.87</td>\n",
       "      <td>9461.73</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2019-07-30</td>\n",
       "      <td>9461.73</td>\n",
       "      <td>9470.46</td>\n",
       "      <td>9402.00</td>\n",
       "      <td>9425.55</td>\n",
       "      <td>1877.784054</td>\n",
       "      <td>1.773400e+07</td>\n",
       "      <td>9726</td>\n",
       "      <td>344.451758</td>\n",
       "      <td>3.250685e+06</td>\n",
       "      <td>9460.42</td>\n",
       "      <td>5.90</td>\n",
       "      <td>9425.60</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Open Time     Open     High      Low    Close       Volume  \\\n",
       "1 2019-07-30  9517.03  9539.00  9507.00  9532.58   258.514869   \n",
       "2 2019-07-30  9533.59  9534.00  9500.00  9500.25   275.797270   \n",
       "3 2019-07-30  9500.25  9514.46  9460.71  9465.25   485.218470   \n",
       "4 2019-07-30  9465.25  9488.94  9430.01  9460.42   498.669626   \n",
       "5 2019-07-30  9461.73  9470.46  9402.00  9425.55  1877.784054   \n",
       "\n",
       "   Quote Asset Volume  Number of Trades  TB Base Volume  TB Quote Volume  \\\n",
       "1        2.462134e+06              3133      141.887550     1.351182e+06   \n",
       "2        2.624322e+06              3583      114.238457     1.087402e+06   \n",
       "3        4.604004e+06              5330      225.681291     2.141459e+06   \n",
       "4        4.717269e+06              6197      228.535910     2.162163e+06   \n",
       "5        1.773400e+07              9726      344.451758     3.250685e+06   \n",
       "\n",
       "   yesterdayGain  tomorrowGain  tomorrowOpen  \n",
       "1        9517.75        -32.33       9533.59  \n",
       "2        9532.58        -35.00       9500.25  \n",
       "3        9500.25         -4.83       9465.25  \n",
       "4        9465.25        -34.87       9461.73  \n",
       "5        9460.42          5.90       9425.60  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "newDF = newDF.dropna(axis=0)\n",
    "newDF.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "learningDF = newDF.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Open Time</th>\n",
       "      <th>Open</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Close</th>\n",
       "      <th>Volume</th>\n",
       "      <th>Quote Asset Volume</th>\n",
       "      <th>Number of Trades</th>\n",
       "      <th>TB Base Volume</th>\n",
       "      <th>TB Quote Volume</th>\n",
       "      <th>yesterdayGain</th>\n",
       "      <th>tomorrowGain</th>\n",
       "      <th>tomorrowOpen</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2019-07-30</td>\n",
       "      <td>9517.03</td>\n",
       "      <td>9539.00</td>\n",
       "      <td>9507.00</td>\n",
       "      <td>9532.58</td>\n",
       "      <td>258.514869</td>\n",
       "      <td>2.462134e+06</td>\n",
       "      <td>3133</td>\n",
       "      <td>141.887550</td>\n",
       "      <td>1.351182e+06</td>\n",
       "      <td>9517.75</td>\n",
       "      <td>-32.33</td>\n",
       "      <td>9533.59</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2019-07-30</td>\n",
       "      <td>9533.59</td>\n",
       "      <td>9534.00</td>\n",
       "      <td>9500.00</td>\n",
       "      <td>9500.25</td>\n",
       "      <td>275.797270</td>\n",
       "      <td>2.624322e+06</td>\n",
       "      <td>3583</td>\n",
       "      <td>114.238457</td>\n",
       "      <td>1.087402e+06</td>\n",
       "      <td>9532.58</td>\n",
       "      <td>-35.00</td>\n",
       "      <td>9500.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2019-07-30</td>\n",
       "      <td>9500.25</td>\n",
       "      <td>9514.46</td>\n",
       "      <td>9460.71</td>\n",
       "      <td>9465.25</td>\n",
       "      <td>485.218470</td>\n",
       "      <td>4.604004e+06</td>\n",
       "      <td>5330</td>\n",
       "      <td>225.681291</td>\n",
       "      <td>2.141459e+06</td>\n",
       "      <td>9500.25</td>\n",
       "      <td>-4.83</td>\n",
       "      <td>9465.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2019-07-30</td>\n",
       "      <td>9465.25</td>\n",
       "      <td>9488.94</td>\n",
       "      <td>9430.01</td>\n",
       "      <td>9460.42</td>\n",
       "      <td>498.669626</td>\n",
       "      <td>4.717269e+06</td>\n",
       "      <td>6197</td>\n",
       "      <td>228.535910</td>\n",
       "      <td>2.162163e+06</td>\n",
       "      <td>9465.25</td>\n",
       "      <td>-34.87</td>\n",
       "      <td>9461.73</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2019-07-30</td>\n",
       "      <td>9461.73</td>\n",
       "      <td>9470.46</td>\n",
       "      <td>9402.00</td>\n",
       "      <td>9425.55</td>\n",
       "      <td>1877.784054</td>\n",
       "      <td>1.773400e+07</td>\n",
       "      <td>9726</td>\n",
       "      <td>344.451758</td>\n",
       "      <td>3.250685e+06</td>\n",
       "      <td>9460.42</td>\n",
       "      <td>5.90</td>\n",
       "      <td>9425.60</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Open Time     Open     High      Low    Close       Volume  \\\n",
       "1 2019-07-30  9517.03  9539.00  9507.00  9532.58   258.514869   \n",
       "2 2019-07-30  9533.59  9534.00  9500.00  9500.25   275.797270   \n",
       "3 2019-07-30  9500.25  9514.46  9460.71  9465.25   485.218470   \n",
       "4 2019-07-30  9465.25  9488.94  9430.01  9460.42   498.669626   \n",
       "5 2019-07-30  9461.73  9470.46  9402.00  9425.55  1877.784054   \n",
       "\n",
       "   Quote Asset Volume  Number of Trades  TB Base Volume  TB Quote Volume  \\\n",
       "1        2.462134e+06              3133      141.887550     1.351182e+06   \n",
       "2        2.624322e+06              3583      114.238457     1.087402e+06   \n",
       "3        4.604004e+06              5330      225.681291     2.141459e+06   \n",
       "4        4.717269e+06              6197      228.535910     2.162163e+06   \n",
       "5        1.773400e+07              9726      344.451758     3.250685e+06   \n",
       "\n",
       "   yesterdayGain  tomorrowGain  tomorrowOpen  \n",
       "1        9517.75        -32.33       9533.59  \n",
       "2        9532.58        -35.00       9500.25  \n",
       "3        9500.25         -4.83       9465.25  \n",
       "4        9465.25        -34.87       9461.73  \n",
       "5        9460.42          5.90       9425.60  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "learningDF.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Open Time</th>\n",
       "      <th>Open</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Close</th>\n",
       "      <th>Volume</th>\n",
       "      <th>Quote Asset Volume</th>\n",
       "      <th>Number of Trades</th>\n",
       "      <th>TB Base Volume</th>\n",
       "      <th>TB Quote Volume</th>\n",
       "      <th>yesterdayGain</th>\n",
       "      <th>tomorrowGain</th>\n",
       "      <th>tomorrowOpen</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2019-07-30</td>\n",
       "      <td>9517.03</td>\n",
       "      <td>9539.00</td>\n",
       "      <td>9507.00</td>\n",
       "      <td>9532.58</td>\n",
       "      <td>258.514869</td>\n",
       "      <td>2.462134e+06</td>\n",
       "      <td>3133</td>\n",
       "      <td>141.887550</td>\n",
       "      <td>1.351182e+06</td>\n",
       "      <td>9517.75</td>\n",
       "      <td>-32.33</td>\n",
       "      <td>9533.59</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2019-07-30</td>\n",
       "      <td>9533.59</td>\n",
       "      <td>9534.00</td>\n",
       "      <td>9500.00</td>\n",
       "      <td>9500.25</td>\n",
       "      <td>275.797270</td>\n",
       "      <td>2.624322e+06</td>\n",
       "      <td>3583</td>\n",
       "      <td>114.238457</td>\n",
       "      <td>1.087402e+06</td>\n",
       "      <td>9532.58</td>\n",
       "      <td>-35.00</td>\n",
       "      <td>9500.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2019-07-30</td>\n",
       "      <td>9500.25</td>\n",
       "      <td>9514.46</td>\n",
       "      <td>9460.71</td>\n",
       "      <td>9465.25</td>\n",
       "      <td>485.218470</td>\n",
       "      <td>4.604004e+06</td>\n",
       "      <td>5330</td>\n",
       "      <td>225.681291</td>\n",
       "      <td>2.141459e+06</td>\n",
       "      <td>9500.25</td>\n",
       "      <td>-4.83</td>\n",
       "      <td>9465.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2019-07-30</td>\n",
       "      <td>9465.25</td>\n",
       "      <td>9488.94</td>\n",
       "      <td>9430.01</td>\n",
       "      <td>9460.42</td>\n",
       "      <td>498.669626</td>\n",
       "      <td>4.717269e+06</td>\n",
       "      <td>6197</td>\n",
       "      <td>228.535910</td>\n",
       "      <td>2.162163e+06</td>\n",
       "      <td>9465.25</td>\n",
       "      <td>-34.87</td>\n",
       "      <td>9461.73</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2019-07-30</td>\n",
       "      <td>9461.73</td>\n",
       "      <td>9470.46</td>\n",
       "      <td>9402.00</td>\n",
       "      <td>9425.55</td>\n",
       "      <td>1877.784054</td>\n",
       "      <td>1.773400e+07</td>\n",
       "      <td>9726</td>\n",
       "      <td>344.451758</td>\n",
       "      <td>3.250685e+06</td>\n",
       "      <td>9460.42</td>\n",
       "      <td>5.90</td>\n",
       "      <td>9425.60</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Open Time     Open     High      Low    Close       Volume  \\\n",
       "1 2019-07-30  9517.03  9539.00  9507.00  9532.58   258.514869   \n",
       "2 2019-07-30  9533.59  9534.00  9500.00  9500.25   275.797270   \n",
       "3 2019-07-30  9500.25  9514.46  9460.71  9465.25   485.218470   \n",
       "4 2019-07-30  9465.25  9488.94  9430.01  9460.42   498.669626   \n",
       "5 2019-07-30  9461.73  9470.46  9402.00  9425.55  1877.784054   \n",
       "\n",
       "   Quote Asset Volume  Number of Trades  TB Base Volume  TB Quote Volume  \\\n",
       "1        2.462134e+06              3133      141.887550     1.351182e+06   \n",
       "2        2.624322e+06              3583      114.238457     1.087402e+06   \n",
       "3        4.604004e+06              5330      225.681291     2.141459e+06   \n",
       "4        4.717269e+06              6197      228.535910     2.162163e+06   \n",
       "5        1.773400e+07              9726      344.451758     3.250685e+06   \n",
       "\n",
       "   yesterdayGain  tomorrowGain  tomorrowOpen  \n",
       "1        9517.75        -32.33       9533.59  \n",
       "2        9532.58        -35.00       9500.25  \n",
       "3        9500.25         -4.83       9465.25  \n",
       "4        9465.25        -34.87       9461.73  \n",
       "5        9460.42          5.90       9425.60  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "learningDF.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "xBase = learningDF[\"Open\"].copy()\n",
    "yBase = learningDF[\"tomorrowOpen\"].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "xTRain, xTest, yTrain, yTest = model_selection.train_test_split(xBase, yBase, test_size =.25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "18583    11849.02\n",
       "31522    44955.35\n",
       "25816    36468.31\n",
       "35795    45862.84\n",
       "25022    31290.53\n",
       "Name: Open, dtype: float64"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xTRain.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "27560    50738.27\n",
       "8929      9336.17\n",
       "22723    15953.73\n",
       "7602      7340.90\n",
       "44673    43598.62\n",
       "Name: Open, dtype: float64"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xTest.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense (Dense)               (None, 8)                 16        \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 1)                 9         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 25\n",
      "Trainable params: 25\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "modelSequential = Sequential()\n",
    "modelSequential.add(layers.Dense(8, input_dim=1, activation='relu'))\n",
    "modelSequential.add(layers.Dense(1))\n",
    "modelSequential.compile(loss='mean_squared_error', optimizer='adam')\n",
    "modelSequential.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Commented out to not accidentally redo model in azure\n",
    "#ws = Workspace.from_config(_file_name='config.json')\n",
    "#mlflow.set_tracking_uri(azFlowWorkspace.get_mlflow_tracking_uri())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022/05/14 19:44:25 INFO mlflow.tracking.fluent: Experiment with name 'finalSequential' does not exist. Creating a new experiment.\n"
     ]
    }
   ],
   "source": [
    "#mlflow.set_experiment('finalSequential')\n",
    "#mlflow.tensorflow.autolog(every_n_iter=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022/05/14 19:44:27 INFO mlflow.utils.autologging_utils: Created MLflow autologging run with ID '67f14752-8d9f-4fa3-b20b-352f5b560f75', which will track hyperparameters, performance metrics, model artifacts, and lineage information for the current tensorflow workflow\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "    1/18245 [..............................] - ETA: 1:05:59 - loss: 1169361664.0000WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0004s vs `on_train_batch_end` time: 0.0020s). Check your callbacks.\n",
      "18245/18245 [==============================] - 10s 555us/step - loss: 7627262.5000\n",
      "Epoch 2/200\n",
      "18245/18245 [==============================] - 9s 496us/step - loss: 54348.3281\n",
      "Epoch 3/200\n",
      "18245/18245 [==============================] - 10s 542us/step - loss: 53520.2656\n",
      "Epoch 4/200\n",
      "18245/18245 [==============================] - 10s 552us/step - loss: 52364.7852\n",
      "Epoch 5/200\n",
      "18245/18245 [==============================] - 10s 559us/step - loss: 52990.6992\n",
      "Epoch 6/200\n",
      "18245/18245 [==============================] - 10s 558us/step - loss: 52661.2383\n",
      "Epoch 7/200\n",
      "18245/18245 [==============================] - 10s 545us/step - loss: 52501.5352\n",
      "Epoch 8/200\n",
      "18245/18245 [==============================] - 10s 533us/step - loss: 52354.1289\n",
      "Epoch 9/200\n",
      "18245/18245 [==============================] - 9s 521us/step - loss: 51174.2461\n",
      "Epoch 10/200\n",
      "18245/18245 [==============================] - 10s 527us/step - loss: 50074.4180\n",
      "Epoch 11/200\n",
      "18245/18245 [==============================] - 10s 540us/step - loss: 50003.3516\n",
      "Epoch 12/200\n",
      "18245/18245 [==============================] - 10s 540us/step - loss: 49923.8047\n",
      "Epoch 13/200\n",
      "18245/18245 [==============================] - 10s 534us/step - loss: 49414.0000\n",
      "Epoch 14/200\n",
      "18245/18245 [==============================] - 10s 528us/step - loss: 49799.4727\n",
      "Epoch 15/200\n",
      "18245/18245 [==============================] - 10s 527us/step - loss: 49884.9883\n",
      "Epoch 16/200\n",
      "18245/18245 [==============================] - 10s 533us/step - loss: 50415.6172\n",
      "Epoch 17/200\n",
      "18245/18245 [==============================] - 10s 525us/step - loss: 49490.0352\n",
      "Epoch 18/200\n",
      "18245/18245 [==============================] - 16s 869us/step - loss: 49202.3086\n",
      "Epoch 19/200\n",
      "18245/18245 [==============================] - 10s 539us/step - loss: 49544.0898\n",
      "Epoch 20/200\n",
      "18245/18245 [==============================] - 10s 538us/step - loss: 49991.0117\n",
      "Epoch 21/200\n",
      "18245/18245 [==============================] - 10s 537us/step - loss: 49950.3477\n",
      "Epoch 22/200\n",
      "18245/18245 [==============================] - 10s 533us/step - loss: 49283.1445\n",
      "Epoch 23/200\n",
      "18245/18245 [==============================] - 10s 537us/step - loss: 48933.1680\n",
      "Epoch 24/200\n",
      "18245/18245 [==============================] - 10s 539us/step - loss: 49439.6641\n",
      "Epoch 25/200\n",
      "18245/18245 [==============================] - 9s 513us/step - loss: 49501.3789\n",
      "Epoch 26/200\n",
      "18245/18245 [==============================] - 10s 531us/step - loss: 49183.4492\n",
      "Epoch 27/200\n",
      "18245/18245 [==============================] - 10s 542us/step - loss: 49267.9844\n",
      "Epoch 28/200\n",
      "18245/18245 [==============================] - 9s 518us/step - loss: 48701.3672\n",
      "Epoch 29/200\n",
      "18245/18245 [==============================] - 10s 530us/step - loss: 49786.9141\n",
      "Epoch 30/200\n",
      "18245/18245 [==============================] - 10s 568us/step - loss: 49270.0156\n",
      "Epoch 31/200\n",
      "18245/18245 [==============================] - 10s 526us/step - loss: 49336.5938\n",
      "Epoch 32/200\n",
      "18245/18245 [==============================] - 10s 524us/step - loss: 49271.1094\n",
      "Epoch 33/200\n",
      "18245/18245 [==============================] - 10s 524us/step - loss: 48537.9727\n",
      "Epoch 34/200\n",
      "18245/18245 [==============================] - 10s 524us/step - loss: 48553.3398\n",
      "Epoch 35/200\n",
      "18245/18245 [==============================] - 10s 533us/step - loss: 49158.5703\n",
      "Epoch 36/200\n",
      "18245/18245 [==============================] - 10s 531us/step - loss: 49217.4102\n",
      "Epoch 37/200\n",
      "18245/18245 [==============================] - 10s 522us/step - loss: 49101.3945\n",
      "Epoch 38/200\n",
      "18245/18245 [==============================] - 10s 529us/step - loss: 49281.1445\n",
      "Epoch 39/200\n",
      "18245/18245 [==============================] - 10s 534us/step - loss: 48596.1484\n",
      "Epoch 40/200\n",
      "18245/18245 [==============================] - 10s 545us/step - loss: 48153.7773\n",
      "Epoch 41/200\n",
      "18245/18245 [==============================] - 10s 521us/step - loss: 48916.9648\n",
      "Epoch 42/200\n",
      "18245/18245 [==============================] - 10s 525us/step - loss: 48313.5000\n",
      "Epoch 43/200\n",
      "18245/18245 [==============================] - 10s 526us/step - loss: 48499.7031\n",
      "Epoch 44/200\n",
      "18245/18245 [==============================] - 10s 527us/step - loss: 48973.6562\n",
      "Epoch 45/200\n",
      "18245/18245 [==============================] - 10s 528us/step - loss: 48688.8516\n",
      "Epoch 46/200\n",
      "18245/18245 [==============================] - 10s 533us/step - loss: 48759.0312\n",
      "Epoch 47/200\n",
      "18245/18245 [==============================] - 10s 526us/step - loss: 47911.7539\n",
      "Epoch 48/200\n",
      "18245/18245 [==============================] - 10s 530us/step - loss: 49336.9414\n",
      "Epoch 49/200\n",
      "18245/18245 [==============================] - 10s 528us/step - loss: 48237.3086\n",
      "Epoch 50/200\n",
      "18245/18245 [==============================] - 10s 549us/step - loss: 48528.3672\n",
      "Epoch 51/200\n",
      "18245/18245 [==============================] - 10s 531us/step - loss: 48185.2773\n",
      "Epoch 52/200\n",
      "18245/18245 [==============================] - 10s 522us/step - loss: 48476.9531\n",
      "Epoch 53/200\n",
      "18245/18245 [==============================] - 9s 510us/step - loss: 48630.8164\n",
      "Epoch 54/200\n",
      "18245/18245 [==============================] - 10s 536us/step - loss: 48230.6289\n",
      "Epoch 55/200\n",
      "18245/18245 [==============================] - 10s 524us/step - loss: 48756.4180\n",
      "Epoch 56/200\n",
      "18245/18245 [==============================] - 10s 527us/step - loss: 47942.2773\n",
      "Epoch 57/200\n",
      "18245/18245 [==============================] - 9s 516us/step - loss: 48802.3477\n",
      "Epoch 58/200\n",
      "18245/18245 [==============================] - 10s 528us/step - loss: 48126.9570\n",
      "Epoch 59/200\n",
      "18245/18245 [==============================] - 10s 533us/step - loss: 47166.2578\n",
      "Epoch 60/200\n",
      "18245/18245 [==============================] - 10s 529us/step - loss: 48097.4023\n",
      "Epoch 61/200\n",
      "18245/18245 [==============================] - 10s 525us/step - loss: 47462.2070\n",
      "Epoch 62/200\n",
      "18245/18245 [==============================] - 10s 558us/step - loss: 47848.2812\n",
      "Epoch 63/200\n",
      "18245/18245 [==============================] - 10s 543us/step - loss: 47042.1406\n",
      "Epoch 64/200\n",
      "18245/18245 [==============================] - 10s 531us/step - loss: 46920.8750\n",
      "Epoch 65/200\n",
      "18245/18245 [==============================] - 10s 524us/step - loss: 46492.0859\n",
      "Epoch 66/200\n",
      "18245/18245 [==============================] - 10s 533us/step - loss: 46295.6719\n",
      "Epoch 67/200\n",
      "18245/18245 [==============================] - 10s 522us/step - loss: 46221.0117\n",
      "Epoch 68/200\n",
      "18245/18245 [==============================] - 10s 535us/step - loss: 45978.8086\n",
      "Epoch 69/200\n",
      "18245/18245 [==============================] - 10s 532us/step - loss: 46646.2305\n",
      "Epoch 70/200\n",
      "18245/18245 [==============================] - 10s 535us/step - loss: 46390.0078\n",
      "Epoch 71/200\n",
      "18245/18245 [==============================] - 9s 520us/step - loss: 46837.5938\n",
      "Epoch 72/200\n",
      "18245/18245 [==============================] - 10s 532us/step - loss: 46175.3984\n",
      "Epoch 73/200\n",
      "18245/18245 [==============================] - 10s 528us/step - loss: 46400.0703\n",
      "Epoch 74/200\n",
      "18245/18245 [==============================] - 10s 524us/step - loss: 46178.6055\n",
      "Epoch 75/200\n",
      "18245/18245 [==============================] - 10s 534us/step - loss: 46306.9375\n",
      "Epoch 76/200\n",
      "18245/18245 [==============================] - 10s 531us/step - loss: 46192.3828\n",
      "Epoch 77/200\n",
      "18245/18245 [==============================] - 10s 530us/step - loss: 46441.0625\n",
      "Epoch 78/200\n",
      "18245/18245 [==============================] - 10s 540us/step - loss: 46065.0508\n",
      "Epoch 79/200\n",
      "18245/18245 [==============================] - 10s 526us/step - loss: 46048.4414\n",
      "Epoch 80/200\n",
      "18245/18245 [==============================] - 10s 529us/step - loss: 46147.1094\n",
      "Epoch 81/200\n",
      "18245/18245 [==============================] - 10s 530us/step - loss: 45699.0195\n",
      "Epoch 82/200\n",
      "18245/18245 [==============================] - 10s 529us/step - loss: 46032.3438\n",
      "Epoch 83/200\n",
      "18245/18245 [==============================] - 10s 528us/step - loss: 45903.7695\n",
      "Epoch 84/200\n",
      "18245/18245 [==============================] - 10s 529us/step - loss: 45705.8711\n",
      "Epoch 85/200\n",
      "18245/18245 [==============================] - 10s 527us/step - loss: 45644.2695\n",
      "Epoch 86/200\n",
      "18245/18245 [==============================] - 10s 530us/step - loss: 45269.1992\n",
      "Epoch 87/200\n",
      "18245/18245 [==============================] - 10s 536us/step - loss: 45304.2031\n",
      "Epoch 88/200\n",
      "18245/18245 [==============================] - 10s 537us/step - loss: 44700.5625\n",
      "Epoch 89/200\n",
      "18245/18245 [==============================] - 10s 530us/step - loss: 44890.2656\n",
      "Epoch 90/200\n",
      "18245/18245 [==============================] - 10s 532us/step - loss: 44489.7305\n",
      "Epoch 91/200\n",
      "18245/18245 [==============================] - 10s 541us/step - loss: 44290.9570\n",
      "Epoch 92/200\n",
      "18245/18245 [==============================] - 10s 547us/step - loss: 44529.8203\n",
      "Epoch 93/200\n",
      "18245/18245 [==============================] - 10s 556us/step - loss: 44182.2227\n",
      "Epoch 94/200\n",
      "18245/18245 [==============================] - 10s 557us/step - loss: 44304.2070\n",
      "Epoch 95/200\n",
      "18245/18245 [==============================] - 10s 540us/step - loss: 44299.2930\n",
      "Epoch 96/200\n",
      "18245/18245 [==============================] - 10s 536us/step - loss: 44198.2617\n",
      "Epoch 97/200\n",
      "18245/18245 [==============================] - 10s 527us/step - loss: 44490.6211\n",
      "Epoch 98/200\n",
      "18245/18245 [==============================] - 10s 542us/step - loss: 44539.6914\n",
      "Epoch 99/200\n",
      "18245/18245 [==============================] - 10s 540us/step - loss: 44793.4219\n",
      "Epoch 100/200\n",
      "18245/18245 [==============================] - 10s 532us/step - loss: 44408.5508\n",
      "Epoch 101/200\n",
      "18245/18245 [==============================] - 10s 539us/step - loss: 44511.6836\n",
      "Epoch 102/200\n",
      "18245/18245 [==============================] - 10s 529us/step - loss: 44659.1953\n",
      "Epoch 103/200\n",
      "18245/18245 [==============================] - 10s 524us/step - loss: 44558.7578\n",
      "Epoch 104/200\n",
      "18245/18245 [==============================] - 9s 520us/step - loss: 44432.5977\n",
      "Epoch 105/200\n",
      "18245/18245 [==============================] - 9s 515us/step - loss: 44348.5742\n",
      "Epoch 106/200\n",
      "18245/18245 [==============================] - 10s 532us/step - loss: 44802.3672\n",
      "Epoch 107/200\n",
      "18245/18245 [==============================] - 10s 526us/step - loss: 44048.6523\n",
      "Epoch 108/200\n",
      "18245/18245 [==============================] - 10s 526us/step - loss: 44388.8008\n",
      "Epoch 109/200\n",
      "18245/18245 [==============================] - 10s 521us/step - loss: 44401.4102\n",
      "Epoch 110/200\n",
      "18245/18245 [==============================] - 10s 522us/step - loss: 44387.3242\n",
      "Epoch 111/200\n",
      "18245/18245 [==============================] - 10s 529us/step - loss: 44201.5898\n",
      "Epoch 112/200\n",
      "18245/18245 [==============================] - 10s 527us/step - loss: 44407.8789\n",
      "Epoch 113/200\n",
      "18245/18245 [==============================] - 10s 523us/step - loss: 44464.6641\n",
      "Epoch 114/200\n",
      "18245/18245 [==============================] - 10s 530us/step - loss: 44923.7109\n",
      "Epoch 115/200\n",
      "18245/18245 [==============================] - 10s 541us/step - loss: 44317.6289\n",
      "Epoch 116/200\n",
      "18245/18245 [==============================] - 10s 529us/step - loss: 44478.9727\n",
      "Epoch 117/200\n",
      "18245/18245 [==============================] - 10s 528us/step - loss: 44585.2930\n",
      "Epoch 118/200\n",
      "18245/18245 [==============================] - 10s 533us/step - loss: 44828.5078\n",
      "Epoch 119/200\n",
      "18245/18245 [==============================] - 10s 533us/step - loss: 44405.4883\n",
      "Epoch 120/200\n",
      "18245/18245 [==============================] - 10s 524us/step - loss: 44493.9141\n",
      "Epoch 121/200\n",
      "18245/18245 [==============================] - 10s 522us/step - loss: 44138.7031\n",
      "Epoch 122/200\n",
      "18245/18245 [==============================] - 9s 518us/step - loss: 44856.5117\n",
      "Epoch 123/200\n",
      "18245/18245 [==============================] - 10s 527us/step - loss: 44432.9102\n",
      "Epoch 124/200\n",
      "18245/18245 [==============================] - 10s 538us/step - loss: 44517.2383\n",
      "Epoch 125/200\n",
      "18245/18245 [==============================] - 9s 521us/step - loss: 44241.0273\n",
      "Epoch 126/200\n",
      "18245/18245 [==============================] - 10s 524us/step - loss: 44462.4102\n",
      "Epoch 127/200\n",
      "18245/18245 [==============================] - 10s 541us/step - loss: 44507.1055\n",
      "Epoch 128/200\n",
      "18245/18245 [==============================] - 10s 526us/step - loss: 44376.8711\n",
      "Epoch 129/200\n",
      "18245/18245 [==============================] - 10s 525us/step - loss: 44423.2148\n",
      "Epoch 130/200\n",
      "18245/18245 [==============================] - 10s 537us/step - loss: 44434.5508\n",
      "Epoch 131/200\n",
      "18245/18245 [==============================] - 10s 527us/step - loss: 44273.8359\n",
      "Epoch 132/200\n",
      "18245/18245 [==============================] - 10s 538us/step - loss: 44535.2812\n",
      "Epoch 133/200\n",
      "18245/18245 [==============================] - 10s 531us/step - loss: 44390.4297\n",
      "Epoch 134/200\n",
      "18245/18245 [==============================] - 9s 519us/step - loss: 44584.6953\n",
      "Epoch 135/200\n",
      "18245/18245 [==============================] - 10s 525us/step - loss: 44458.1562\n",
      "Epoch 136/200\n",
      "18245/18245 [==============================] - 10s 524us/step - loss: 44732.0195\n",
      "Epoch 137/200\n",
      "18245/18245 [==============================] - 9s 519us/step - loss: 44264.3008\n",
      "Epoch 138/200\n",
      "18245/18245 [==============================] - 10s 529us/step - loss: 44625.5898\n",
      "Epoch 139/200\n",
      "18245/18245 [==============================] - 10s 524us/step - loss: 44640.7930\n",
      "Epoch 140/200\n",
      "18245/18245 [==============================] - 10s 529us/step - loss: 44319.7422\n",
      "Epoch 141/200\n",
      "18245/18245 [==============================] - 10s 527us/step - loss: 44561.4922\n",
      "Epoch 142/200\n",
      "18245/18245 [==============================] - 10s 534us/step - loss: 44432.6562\n",
      "Epoch 143/200\n",
      "18245/18245 [==============================] - 10s 541us/step - loss: 44483.8164\n",
      "Epoch 144/200\n",
      "18245/18245 [==============================] - 10s 537us/step - loss: 44798.0156\n",
      "Epoch 145/200\n",
      "18245/18245 [==============================] - 10s 531us/step - loss: 44576.8281\n",
      "Epoch 146/200\n",
      "18245/18245 [==============================] - 10s 532us/step - loss: 44692.6172\n",
      "Epoch 147/200\n",
      "18245/18245 [==============================] - 16s 859us/step - loss: 44383.9375\n",
      "Epoch 148/200\n",
      "18245/18245 [==============================] - 10s 524us/step - loss: 44111.3906\n",
      "Epoch 149/200\n",
      "18245/18245 [==============================] - 10s 526us/step - loss: 44619.9453\n",
      "Epoch 150/200\n",
      "18245/18245 [==============================] - 10s 525us/step - loss: 44374.6445\n",
      "Epoch 151/200\n",
      "18245/18245 [==============================] - 9s 517us/step - loss: 44439.3633\n",
      "Epoch 152/200\n",
      "18245/18245 [==============================] - 10s 526us/step - loss: 44528.8008\n",
      "Epoch 153/200\n",
      "18245/18245 [==============================] - 9s 520us/step - loss: 44173.0664\n",
      "Epoch 154/200\n",
      "18245/18245 [==============================] - 10s 525us/step - loss: 44381.6406\n",
      "Epoch 155/200\n",
      "18245/18245 [==============================] - 10s 529us/step - loss: 44531.8633\n",
      "Epoch 156/200\n",
      "18245/18245 [==============================] - 10s 523us/step - loss: 44312.2539\n",
      "Epoch 157/200\n",
      "18245/18245 [==============================] - 10s 538us/step - loss: 44299.0742\n",
      "Epoch 158/200\n",
      "18245/18245 [==============================] - 10s 528us/step - loss: 44103.3945\n",
      "Epoch 159/200\n",
      "18245/18245 [==============================] - 10s 524us/step - loss: 44703.8633\n",
      "Epoch 160/200\n",
      "18245/18245 [==============================] - 9s 510us/step - loss: 44208.1797\n",
      "Epoch 161/200\n",
      "18245/18245 [==============================] - 10s 524us/step - loss: 44374.5625\n",
      "Epoch 162/200\n",
      "18245/18245 [==============================] - 10s 533us/step - loss: 44321.3203\n",
      "Epoch 163/200\n",
      "18245/18245 [==============================] - 9s 520us/step - loss: 44084.9531\n",
      "Epoch 164/200\n",
      "18245/18245 [==============================] - 10s 529us/step - loss: 44326.8867\n",
      "Epoch 165/200\n",
      "18245/18245 [==============================] - 10s 538us/step - loss: 44654.6133\n",
      "Epoch 166/200\n",
      "18245/18245 [==============================] - 9s 518us/step - loss: 44426.4141\n",
      "Epoch 167/200\n",
      "18245/18245 [==============================] - 9s 518us/step - loss: 44091.0547\n",
      "Epoch 168/200\n",
      "18245/18245 [==============================] - 9s 509us/step - loss: 44561.0547\n",
      "Epoch 169/200\n",
      "18245/18245 [==============================] - 9s 517us/step - loss: 44108.3750\n",
      "Epoch 170/200\n",
      "18245/18245 [==============================] - 10s 528us/step - loss: 44474.5508\n",
      "Epoch 171/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18245/18245 [==============================] - 10s 530us/step - loss: 44324.8516\n",
      "Epoch 172/200\n",
      "18245/18245 [==============================] - 9s 517us/step - loss: 44628.8555\n",
      "Epoch 173/200\n",
      "18245/18245 [==============================] - 10s 522us/step - loss: 44152.8477\n",
      "Epoch 174/200\n",
      "18245/18245 [==============================] - 10s 544us/step - loss: 44593.9023\n",
      "Epoch 175/200\n",
      "18245/18245 [==============================] - 16s 868us/step - loss: 44346.2031\n",
      "Epoch 176/200\n",
      "18245/18245 [==============================] - 9s 512us/step - loss: 44510.2383\n",
      "Epoch 177/200\n",
      "18245/18245 [==============================] - 9s 521us/step - loss: 44543.0469\n",
      "Epoch 178/200\n",
      "18245/18245 [==============================] - 10s 572us/step - loss: 44819.5391\n",
      "Epoch 179/200\n",
      "18245/18245 [==============================] - 10s 566us/step - loss: 44407.3711\n",
      "Epoch 180/200\n",
      "18245/18245 [==============================] - 10s 534us/step - loss: 44740.5781\n",
      "Epoch 181/200\n",
      "18245/18245 [==============================] - 10s 537us/step - loss: 43851.0273\n",
      "Epoch 182/200\n",
      "18245/18245 [==============================] - 10s 532us/step - loss: 44304.4570\n",
      "Epoch 183/200\n",
      "18245/18245 [==============================] - 10s 524us/step - loss: 44065.1484\n",
      "Epoch 184/200\n",
      "18245/18245 [==============================] - 9s 518us/step - loss: 44848.8242\n",
      "Epoch 185/200\n",
      "18245/18245 [==============================] - 10s 541us/step - loss: 44136.0078\n",
      "Epoch 186/200\n",
      "18245/18245 [==============================] - 10s 566us/step - loss: 44090.0508\n",
      "Epoch 187/200\n",
      "18245/18245 [==============================] - 10s 528us/step - loss: 44204.4297\n",
      "Epoch 188/200\n",
      "18245/18245 [==============================] - 10s 529us/step - loss: 44291.2109\n",
      "Epoch 189/200\n",
      "18245/18245 [==============================] - 10s 540us/step - loss: 44938.7266\n",
      "Epoch 190/200\n",
      "18245/18245 [==============================] - 10s 532us/step - loss: 44297.0156\n",
      "Epoch 191/200\n",
      "18245/18245 [==============================] - 10s 532us/step - loss: 45059.4219\n",
      "Epoch 192/200\n",
      "18245/18245 [==============================] - 10s 528us/step - loss: 44339.6680\n",
      "Epoch 193/200\n",
      "18245/18245 [==============================] - 10s 539us/step - loss: 44377.6758\n",
      "Epoch 194/200\n",
      "18245/18245 [==============================] - 10s 531us/step - loss: 44283.6680\n",
      "Epoch 195/200\n",
      "18245/18245 [==============================] - 10s 534us/step - loss: 44180.4336\n",
      "Epoch 196/200\n",
      "18245/18245 [==============================] - 10s 525us/step - loss: 44116.4453\n",
      "Epoch 197/200\n",
      "18245/18245 [==============================] - 10s 544us/step - loss: 44376.2969\n",
      "Epoch 198/200\n",
      "18245/18245 [==============================] - 10s 542us/step - loss: 44563.5273\n",
      "Epoch 199/200\n",
      "18245/18245 [==============================] - 10s 528us/step - loss: 44323.3594\n",
      "Epoch 200/200\n",
      "18245/18245 [==============================] - 9s 518us/step - loss: 44621.8750\n",
      "INFO:tensorflow:Assets written to: C:\\Users\\Martynow\\AppData\\Local\\Temp\\tmphjruppa5\\model\\data\\model\\assets\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1423ad3ac40>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "modelSequential.fit(xTRain, yTrain, epochs=200, batch_size=2, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Score: 40750.51 MSE (201.87 RMSE)\n",
      "Test Score: 40078.95 MSE (200.20 RMSE)\n"
     ]
    }
   ],
   "source": [
    "# Estimate model performance\n",
    "trainScore = modelSequential.evaluate(xTRain, yTrain, verbose=0)\n",
    "print('Train Score: %.2f MSE (%.2f RMSE)' % (trainScore, math.sqrt(trainScore)))\n",
    "testScore = modelSequential.evaluate(xTest, yTest, verbose=0)\n",
    "print('Test Score: %.2f MSE (%.2f RMSE)' % (testScore, math.sqrt(testScore)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[11856.49 ],\n",
       "       [45235.094],\n",
       "       [36586.58 ],\n",
       "       ...,\n",
       "       [ 9297.213],\n",
       "       [34442.99 ],\n",
       "       [ 6208.981]], dtype=float32)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "modelSequential.predict(yTrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pandas.core.series.Series"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(yTest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(learningDF[\"tomorrowOpen\"], label='original')\n",
    "plt.plot(modelSequential.predict(learningDF[\"Open\"]), label='predicted')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "#mlflow.tensorflow.autolog(disable=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Not great accuracy, what other way to do this?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set a fixed random seed to improve reproducibility\n",
    "np.random.seed(7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "#make the scalers and the data\n",
    "x_scaler = MinMaxScaler(feature_range=(-1, 1))\n",
    "y_scaler = MinMaxScaler(feature_range=(-1, 1))\n",
    "x = learningDF['Open'].copy()\n",
    "y = learningDF['tomorrowOpen'].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "xBase = x_scaler.fit_transform(x.values.reshape(-1, 1))\n",
    "yBase = y_scaler.fit_transform(y.values.reshape(-1, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "xTRain, xTest, yTrain, yTest = model_selection.train_test_split(xBase, yBase, test_size =.25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(36489, 1) (36489, 1) (12164, 1) (12164, 1)\n",
      "[0.35442188] [0.35829359]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(xTRain.shape, yTrain.shape, xTest.shape, yTest.shape)\n",
    "print (xTRain[0], yTrain[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "modelLTSM = Sequential()\n",
    "modelLTSM.add(layers.LSTM(4, input_shape=(1, 1)))\n",
    "modelLTSM.add(layers.Dense(1))\n",
    "modelLTSM.compile(loss='mean_squared_error', optimizer='adam')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " lstm (LSTM)                 (None, 4)                 96        \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 1)                 5         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 101\n",
      "Trainable params: 101\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "modelLTSM.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "#mlflow.set_experiment('finalLTSM')\n",
    "#mlflow.tensorflow.autolog(disable = False, every_n_iter=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022/05/15 11:01:01 INFO mlflow.utils.autologging_utils: Created MLflow autologging run with ID '345a5113-6a45-44ee-b0c9-4af15d2920cf', which will track hyperparameters, performance metrics, model artifacts, and lineage information for the current tensorflow workflow\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "    1/36489 [..............................] - ETA: 10:05:13 - loss: 0.5158WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0010s vs `on_train_batch_end` time: 0.0067s). Check your callbacks.\n",
      "36489/36489 [==============================] - 32s 857us/step - loss: 0.0042\n",
      "Epoch 2/100\n",
      "36489/36489 [==============================] - 31s 852us/step - loss: 5.3067e-05\n",
      "Epoch 3/100\n",
      "36489/36489 [==============================] - 31s 851us/step - loss: 5.3152e-05\n",
      "Epoch 4/100\n",
      "36489/36489 [==============================] - 33s 896us/step - loss: 5.3123e-05\n",
      "Epoch 5/100\n",
      "36489/36489 [==============================] - 32s 878us/step - loss: 5.2585e-05\n",
      "Epoch 6/100\n",
      "36489/36489 [==============================] - 31s 849us/step - loss: 5.2095e-05\n",
      "Epoch 7/100\n",
      "36489/36489 [==============================] - 31s 848us/step - loss: 5.2266e-05\n",
      "Epoch 8/100\n",
      "36489/36489 [==============================] - 31s 844us/step - loss: 5.1641e-05\n",
      "Epoch 9/100\n",
      "36489/36489 [==============================] - 33s 911us/step - loss: 5.1587e-05\n",
      "Epoch 10/100\n",
      "36489/36489 [==============================] - 31s 852us/step - loss: 5.1229e-05\n",
      "Epoch 11/100\n",
      "36489/36489 [==============================] - 31s 838us/step - loss: 5.0695e-05\n",
      "Epoch 12/100\n",
      "36489/36489 [==============================] - 31s 849us/step - loss: 5.0516e-05\n",
      "Epoch 13/100\n",
      "36489/36489 [==============================] - 31s 854us/step - loss: 4.9871e-05\n",
      "Epoch 14/100\n",
      "36489/36489 [==============================] - 31s 853us/step - loss: 5.0811e-05\n",
      "Epoch 15/100\n",
      "36489/36489 [==============================] - 31s 852us/step - loss: 4.9861e-05\n",
      "Epoch 16/100\n",
      "36489/36489 [==============================] - 31s 858us/step - loss: 4.9618e-05\n",
      "Epoch 17/100\n",
      "36489/36489 [==============================] - 31s 852us/step - loss: 4.9446e-05\n",
      "Epoch 18/100\n",
      "36489/36489 [==============================] - 31s 846us/step - loss: 4.9099e-05\n",
      "Epoch 19/100\n",
      "36489/36489 [==============================] - 32s 889us/step - loss: 4.8669e-05\n",
      "Epoch 20/100\n",
      "36489/36489 [==============================] - 32s 875us/step - loss: 4.8380e-05\n",
      "Epoch 21/100\n",
      "36489/36489 [==============================] - 32s 869us/step - loss: 4.8285e-05\n",
      "Epoch 22/100\n",
      "36489/36489 [==============================] - 32s 877us/step - loss: 4.8110e-05\n",
      "Epoch 23/100\n",
      "36489/36489 [==============================] - 32s 863us/step - loss: 4.7548e-05\n",
      "Epoch 24/100\n",
      "36489/36489 [==============================] - 31s 859us/step - loss: 4.7420e-05\n",
      "Epoch 25/100\n",
      "36489/36489 [==============================] - 37s 1ms/step - loss: 4.7299e-05\n",
      "Epoch 26/100\n",
      "36489/36489 [==============================] - 33s 897us/step - loss: 4.6851e-05\n",
      "Epoch 27/100\n",
      "36489/36489 [==============================] - 37s 1ms/step - loss: 4.6416e-05\n",
      "Epoch 28/100\n",
      "36489/36489 [==============================] - 31s 857us/step - loss: 4.6501e-05\n",
      "Epoch 29/100\n",
      "36489/36489 [==============================] - 31s 863us/step - loss: 4.6131e-05\n",
      "Epoch 30/100\n",
      "36489/36489 [==============================] - 32s 864us/step - loss: 4.5928e-05\n",
      "Epoch 31/100\n",
      "36489/36489 [==============================] - 31s 841us/step - loss: 4.6000e-05\n",
      "Epoch 32/100\n",
      "36489/36489 [==============================] - 31s 856us/step - loss: 4.5759e-05\n",
      "Epoch 33/100\n",
      "36489/36489 [==============================] - 37s 1ms/step - loss: 4.5499e-05\n",
      "Epoch 34/100\n",
      "36489/36489 [==============================] - 31s 851us/step - loss: 4.5273e-05\n",
      "Epoch 35/100\n",
      "36489/36489 [==============================] - 31s 851us/step - loss: 4.5319e-05\n",
      "Epoch 36/100\n",
      "36489/36489 [==============================] - 31s 853us/step - loss: 4.5408e-05\n",
      "Epoch 37/100\n",
      "36489/36489 [==============================] - 31s 863us/step - loss: 4.4679e-05\n",
      "Epoch 38/100\n",
      "36489/36489 [==============================] - 31s 857us/step - loss: 4.5607e-05\n",
      "Epoch 39/100\n",
      "36489/36489 [==============================] - 32s 863us/step - loss: 4.5210e-05\n",
      "Epoch 40/100\n",
      "36489/36489 [==============================] - 31s 855us/step - loss: 4.4873e-05\n",
      "Epoch 41/100\n",
      "36489/36489 [==============================] - 31s 851us/step - loss: 4.4944e-05\n",
      "Epoch 42/100\n",
      "36489/36489 [==============================] - 31s 848us/step - loss: 4.4929e-05\n",
      "Epoch 43/100\n",
      "36489/36489 [==============================] - 31s 853us/step - loss: 4.4689e-05\n",
      "Epoch 44/100\n",
      "36489/36489 [==============================] - 31s 852us/step - loss: 4.4876e-05\n",
      "Epoch 45/100\n",
      "36489/36489 [==============================] - 37s 1ms/step - loss: 4.4757e-05\n",
      "Epoch 46/100\n",
      "36489/36489 [==============================] - 31s 848us/step - loss: 4.5029e-05\n",
      "Epoch 47/100\n",
      "36489/36489 [==============================] - 31s 855us/step - loss: 4.4623e-05\n",
      "Epoch 48/100\n",
      "36489/36489 [==============================] - 31s 860us/step - loss: 4.4633e-05\n",
      "Epoch 49/100\n",
      "36489/36489 [==============================] - 38s 1ms/step - loss: 4.4861e-05\n",
      "Epoch 50/100\n",
      "36489/36489 [==============================] - 31s 862us/step - loss: 4.4202e-05\n",
      "Epoch 51/100\n",
      "36489/36489 [==============================] - 31s 856us/step - loss: 4.4541e-05\n",
      "Epoch 52/100\n",
      "36489/36489 [==============================] - 31s 854us/step - loss: 4.4461e-05\n",
      "Epoch 53/100\n",
      "36489/36489 [==============================] - 31s 849us/step - loss: 4.4557e-05\n",
      "Epoch 54/100\n",
      "36489/36489 [==============================] - 31s 849us/step - loss: 4.3971e-05\n",
      "Epoch 55/100\n",
      "36489/36489 [==============================] - 31s 849us/step - loss: 4.4156e-05\n",
      "Epoch 56/100\n",
      "36489/36489 [==============================] - 31s 849us/step - loss: 4.4317e-05\n",
      "Epoch 57/100\n",
      "36489/36489 [==============================] - 31s 851us/step - loss: 4.4230e-05\n",
      "Epoch 58/100\n",
      "36489/36489 [==============================] - 31s 843us/step - loss: 4.4146e-05\n",
      "Epoch 59/100\n",
      "36489/36489 [==============================] - 31s 861us/step - loss: 4.4311e-05\n",
      "Epoch 60/100\n",
      "36489/36489 [==============================] - 31s 853us/step - loss: 4.4318e-05\n",
      "Epoch 61/100\n",
      "36489/36489 [==============================] - 31s 851us/step - loss: 4.4379e-05\n",
      "Epoch 62/100\n",
      "36489/36489 [==============================] - 31s 842us/step - loss: 4.4024e-05\n",
      "Epoch 63/100\n",
      "36489/36489 [==============================] - 31s 853us/step - loss: 4.3839e-05\n",
      "Epoch 64/100\n",
      "36489/36489 [==============================] - 31s 846us/step - loss: 4.4168e-05\n",
      "Epoch 65/100\n",
      "36489/36489 [==============================] - 31s 844us/step - loss: 4.4116e-05\n",
      "Epoch 66/100\n",
      "36489/36489 [==============================] - 37s 1ms/step - loss: 4.3766e-05\n",
      "Epoch 67/100\n",
      "36489/36489 [==============================] - 31s 847us/step - loss: 4.4058e-05\n",
      "Epoch 68/100\n",
      "36489/36489 [==============================] - 31s 850us/step - loss: 4.3801e-05\n",
      "Epoch 69/100\n",
      "36489/36489 [==============================] - 32s 865us/step - loss: 4.4104e-05\n",
      "Epoch 70/100\n",
      "36489/36489 [==============================] - 31s 842us/step - loss: 4.3711e-05\n",
      "Epoch 71/100\n",
      "36489/36489 [==============================] - 31s 850us/step - loss: 4.3815e-05\n",
      "Epoch 72/100\n",
      "36489/36489 [==============================] - 31s 854us/step - loss: 4.4165e-05\n",
      "Epoch 73/100\n",
      "36489/36489 [==============================] - 31s 846us/step - loss: 4.4445e-05\n",
      "Epoch 74/100\n",
      "36489/36489 [==============================] - 31s 840us/step - loss: 4.3883e-05\n",
      "Epoch 75/100\n",
      "36489/36489 [==============================] - 31s 854us/step - loss: 4.3820e-05\n",
      "Epoch 76/100\n",
      "36489/36489 [==============================] - 31s 856us/step - loss: 4.3777e-05\n",
      "Epoch 77/100\n",
      "36489/36489 [==============================] - 31s 856us/step - loss: 4.3604e-05\n",
      "Epoch 78/100\n",
      "36489/36489 [==============================] - 31s 856us/step - loss: 4.4090e-05\n",
      "Epoch 79/100\n",
      "36489/36489 [==============================] - 32s 870us/step - loss: 4.3590e-05\n",
      "Epoch 80/100\n",
      "36489/36489 [==============================] - 31s 861us/step - loss: 4.4160e-05\n",
      "Epoch 81/100\n",
      "36489/36489 [==============================] - 31s 857us/step - loss: 4.3816e-05\n",
      "Epoch 82/100\n",
      "36489/36489 [==============================] - 37s 1ms/step - loss: 4.3734e-05\n",
      "Epoch 83/100\n",
      "36489/36489 [==============================] - 31s 855us/step - loss: 4.3613e-05\n",
      "Epoch 84/100\n",
      "36489/36489 [==============================] - 31s 860us/step - loss: 4.3886e-05\n",
      "Epoch 85/100\n",
      "36489/36489 [==============================] - 31s 853us/step - loss: 4.3636e-05\n",
      "Epoch 86/100\n",
      "36489/36489 [==============================] - 31s 852us/step - loss: 4.3487e-05\n",
      "Epoch 87/100\n",
      "36489/36489 [==============================] - 31s 853us/step - loss: 4.3645e-05\n",
      "Epoch 88/100\n",
      "36489/36489 [==============================] - 31s 854us/step - loss: 4.3788e-05\n",
      "Epoch 89/100\n",
      "36489/36489 [==============================] - 31s 853us/step - loss: 4.3551e-05\n",
      "Epoch 90/100\n",
      "36489/36489 [==============================] - 31s 854us/step - loss: 4.3854e-05\n",
      "Epoch 91/100\n",
      "36489/36489 [==============================] - 30s 832us/step - loss: 4.3816e-05\n",
      "Epoch 92/100\n",
      "36489/36489 [==============================] - 31s 852us/step - loss: 4.3733e-05\n",
      "Epoch 93/100\n",
      "36489/36489 [==============================] - 31s 845us/step - loss: 4.3657e-05\n",
      "Epoch 94/100\n",
      "36489/36489 [==============================] - 32s 872us/step - loss: 4.3751e-05\n",
      "Epoch 95/100\n",
      "36489/36489 [==============================] - 31s 847us/step - loss: 4.3679e-05\n",
      "Epoch 96/100\n",
      "36489/36489 [==============================] - 31s 849us/step - loss: 4.3509e-05\n",
      "Epoch 97/100\n",
      "36489/36489 [==============================] - 31s 855us/step - loss: 4.3633e-05\n",
      "Epoch 98/100\n",
      "36489/36489 [==============================] - 31s 857us/step - loss: 4.3635e-05\n",
      "Epoch 99/100\n",
      "36489/36489 [==============================] - 31s 857us/step - loss: 4.3507e-05\n",
      "Epoch 100/100\n",
      "36489/36489 [==============================] - 31s 848us/step - loss: 4.3412e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as lstm_cell_layer_call_fn, lstm_cell_layer_call_and_return_conditional_losses while saving (showing 2 of 2). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:\\Users\\Martynow\\AppData\\Local\\Temp\\tmpuxfd5xo5\\model\\data\\model\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:\\Users\\Martynow\\AppData\\Local\\Temp\\tmpuxfd5xo5\\model\\data\\model\\assets\n",
      "WARNING:absl:<keras.layers.recurrent.LSTMCell object at 0x000001423AB5DA30> has the same name 'LSTMCell' as a built-in Keras object. Consider renaming <class 'keras.layers.recurrent.LSTMCell'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1422531eb80>"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "modelLTSM.fit(xTRain, yTrain, epochs=100, batch_size=1, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Score: 0.00 MSE (0.01 RMSE)\n",
      "Test Score: 0.00 MSE (0.01 RMSE)\n"
     ]
    }
   ],
   "source": [
    "trainScore = modelLTSM.evaluate(xTRain, yTrain, verbose=0)\n",
    "print('Train Score: %.2f MSE (%.2f RMSE)' % (trainScore, math.sqrt(trainScore)))\n",
    "testScore = modelLTSM.evaluate(xTest, yTest, verbose=0)\n",
    "print('Test Score: %.2f MSE (%.2f RMSE)' % (testScore, math.sqrt(testScore)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "#mlflow.tensorflow.autolog(disable = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.35442188],\n",
       "       [-0.80954203],\n",
       "       [ 0.39113998],\n",
       "       ...,\n",
       "       [-0.80585078],\n",
       "       [ 0.57964644],\n",
       "       [-0.88729176]])"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xTRain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    9517.03\n",
       "2    9533.59\n",
       "3    9500.25\n",
       "4    9465.25\n",
       "5    9461.73\n",
       "Name: Open, dtype: float64"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "learningDF[\"Open\"].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataSet = learningDF[\"Open\"].values\n",
    "dataSet = dataSet.astype('float32')\n",
    "train_size = int(len(dataSet) * 0.67)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = MinMaxScaler(feature_range=(-1, 1))\n",
    "dataSet = scaler.fit_transform(dataSet.reshape(-1,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32597 16056\n"
     ]
    }
   ],
   "source": [
    "test_size = len(dataSet) - train_size\n",
    "train, test = dataSet[0:train_size,:], dataSet[train_size:len(dataSet),:]\n",
    "print(len(train), len(test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert an array of values into a dataset matrix because the shift method used before was messing up the MSE hard\n",
    "def create_dataset(dataset, look_back=1):\n",
    "    dataX, dataY = [], []\n",
    "    for i in range(len(dataset)-look_back-1):\n",
    "        a = dataset[i:(i+look_back), 0]\n",
    "        dataX.append(a)\n",
    "        dataY.append(dataset[i + look_back, 0])\n",
    "    return np.array(dataX), np.array(dataY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reshape into X=t and Y=t+1\n",
    "look_back = 1\n",
    "trainX, trainY = create_dataset(train, look_back)\n",
    "testX, testY = create_dataset(test, look_back)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reshape input to be [samples, time steps, features]\n",
    "trainX = np.reshape(trainX, (trainX.shape[0], 1, trainX.shape[1]))\n",
    "testX = np.reshape(testX, (testX.shape[0], 1, testX.shape[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022/05/15 11:54:08 INFO mlflow.tracking.fluent: Experiment with name 'finalLTSMScaled' does not exist. Creating a new experiment.\n"
     ]
    }
   ],
   "source": [
    "#mlflow.set_experiment('finalLTSMScaled')\n",
    "#mlflow.tensorflow.autolog(disable = False, every_n_iter=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "modelLTSMScaled = Sequential()\n",
    "modelLTSMScaled.add(layers.LSTM(4, input_shape=(1, 1)))\n",
    "modelLTSMScaled.add(layers.Dense(1))\n",
    "modelLTSMScaled.compile(loss='mean_squared_error', optimizer='adam')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022/05/15 11:54:09 INFO mlflow.utils.autologging_utils: Created MLflow autologging run with ID 'd9b88dee-6429-4c45-8aed-a06fa4bb703d', which will track hyperparameters, performance metrics, model artifacts, and lineage information for the current tensorflow workflow\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "    1/32595 [..............................] - ETA: 7:26:38 - loss: 0.6550WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0010s vs `on_train_batch_end` time: 0.0065s). Check your callbacks.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0010s vs `on_train_batch_end` time: 0.0065s). Check your callbacks.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32595/32595 [==============================] - 29s 878us/step - loss: 0.0039\n",
      "Epoch 2/100\n",
      "32595/32595 [==============================] - 28s 859us/step - loss: 8.1686e-05\n",
      "Epoch 3/100\n",
      "32595/32595 [==============================] - 28s 869us/step - loss: 6.4228e-05\n",
      "Epoch 4/100\n",
      "32595/32595 [==============================] - 28s 854us/step - loss: 5.1221e-05\n",
      "Epoch 5/100\n",
      "32595/32595 [==============================] - 34s 1ms/step - loss: 4.8129e-05\n",
      "Epoch 6/100\n",
      "32595/32595 [==============================] - 28s 855us/step - loss: 4.6333e-05\n",
      "Epoch 7/100\n",
      "32595/32595 [==============================] - 28s 851us/step - loss: 4.5993e-05\n",
      "Epoch 8/100\n",
      "32595/32595 [==============================] - 34s 1ms/step - loss: 4.5564e-05\n",
      "Epoch 9/100\n",
      "32595/32595 [==============================] - 28s 860us/step - loss: 4.5612e-05\n",
      "Epoch 10/100\n",
      "32595/32595 [==============================] - 28s 858us/step - loss: 4.4610e-05\n",
      "Epoch 11/100\n",
      "32595/32595 [==============================] - 28s 856us/step - loss: 4.3679e-05\n",
      "Epoch 12/100\n",
      "32595/32595 [==============================] - 28s 866us/step - loss: 4.3814e-05\n",
      "Epoch 13/100\n",
      "32595/32595 [==============================] - 29s 881us/step - loss: 4.2693e-05\n",
      "Epoch 14/100\n",
      "32595/32595 [==============================] - 28s 872us/step - loss: 4.2837e-05\n",
      "Epoch 15/100\n",
      "32595/32595 [==============================] - 28s 860us/step - loss: 4.3071e-05\n",
      "Epoch 16/100\n",
      "32595/32595 [==============================] - 28s 856us/step - loss: 4.2617e-05\n",
      "Epoch 17/100\n",
      "32595/32595 [==============================] - 28s 849us/step - loss: 4.2114e-05\n",
      "Epoch 18/100\n",
      "32595/32595 [==============================] - 28s 857us/step - loss: 4.2007e-05\n",
      "Epoch 19/100\n",
      "32595/32595 [==============================] - 28s 860us/step - loss: 4.2085e-05\n",
      "Epoch 20/100\n",
      "32595/32595 [==============================] - 28s 860us/step - loss: 4.2676e-05\n",
      "Epoch 21/100\n",
      "32595/32595 [==============================] - 28s 866us/step - loss: 4.1765e-05\n",
      "Epoch 22/100\n",
      "32595/32595 [==============================] - 28s 870us/step - loss: 4.1545e-05\n",
      "Epoch 23/100\n",
      "32595/32595 [==============================] - 28s 863us/step - loss: 4.1526e-05\n",
      "Epoch 24/100\n",
      "32595/32595 [==============================] - 28s 857us/step - loss: 4.0789e-05\n",
      "Epoch 25/100\n",
      "32595/32595 [==============================] - 28s 864us/step - loss: 4.1644e-05\n",
      "Epoch 26/100\n",
      "32595/32595 [==============================] - 28s 867us/step - loss: 4.0905e-05\n",
      "Epoch 27/100\n",
      "32595/32595 [==============================] - 28s 864us/step - loss: 4.0986e-05\n",
      "Epoch 28/100\n",
      "32595/32595 [==============================] - 38s 1ms/step - loss: 4.0800e-05\n",
      "Epoch 29/100\n",
      "32595/32595 [==============================] - 28s 855us/step - loss: 4.0541e-05\n",
      "Epoch 30/100\n",
      "32595/32595 [==============================] - 28s 859us/step - loss: 4.0302e-05\n",
      "Epoch 31/100\n",
      "32595/32595 [==============================] - 29s 898us/step - loss: 4.0587e-05\n",
      "Epoch 32/100\n",
      "32595/32595 [==============================] - 28s 858us/step - loss: 4.0269e-05\n",
      "Epoch 33/100\n",
      "32595/32595 [==============================] - 29s 877us/step - loss: 4.0009e-05\n",
      "Epoch 34/100\n",
      "32595/32595 [==============================] - 28s 867us/step - loss: 4.0140e-05\n",
      "Epoch 35/100\n",
      "32595/32595 [==============================] - 28s 862us/step - loss: 3.9930e-05\n",
      "Epoch 36/100\n",
      "32595/32595 [==============================] - 28s 864us/step - loss: 4.0236e-05\n",
      "Epoch 37/100\n",
      "32595/32595 [==============================] - 28s 863us/step - loss: 3.9676e-05\n",
      "Epoch 38/100\n",
      "32595/32595 [==============================] - 34s 1ms/step - loss: 3.9315e-05\n",
      "Epoch 39/100\n",
      "32595/32595 [==============================] - 28s 852us/step - loss: 3.9611e-05\n",
      "Epoch 40/100\n",
      "32595/32595 [==============================] - 28s 856us/step - loss: 3.9368e-05\n",
      "Epoch 41/100\n",
      "32595/32595 [==============================] - 28s 857us/step - loss: 3.9161e-05\n",
      "Epoch 42/100\n",
      "32595/32595 [==============================] - 28s 866us/step - loss: 3.8848e-05\n",
      "Epoch 43/100\n",
      "32595/32595 [==============================] - 28s 865us/step - loss: 3.9356e-05\n",
      "Epoch 44/100\n",
      "32595/32595 [==============================] - 28s 874us/step - loss: 3.9000e-05\n",
      "Epoch 45/100\n",
      "32595/32595 [==============================] - 28s 860us/step - loss: 3.8629e-05\n",
      "Epoch 46/100\n",
      "32595/32595 [==============================] - 28s 857us/step - loss: 3.8742e-05\n",
      "Epoch 47/100\n",
      "32595/32595 [==============================] - 28s 857us/step - loss: 3.8301e-05\n",
      "Epoch 48/100\n",
      "32595/32595 [==============================] - 29s 891us/step - loss: 3.8660e-05\n",
      "Epoch 49/100\n",
      "32595/32595 [==============================] - 28s 859us/step - loss: 3.8263e-05\n",
      "Epoch 50/100\n",
      "32595/32595 [==============================] - 28s 865us/step - loss: 3.8339e-05\n",
      "Epoch 51/100\n",
      "32595/32595 [==============================] - 28s 858us/step - loss: 3.7793e-05\n",
      "Epoch 52/100\n",
      "32595/32595 [==============================] - 28s 858us/step - loss: 3.8451e-05\n",
      "Epoch 53/100\n",
      "32595/32595 [==============================] - 28s 861us/step - loss: 3.8196e-05\n",
      "Epoch 54/100\n",
      "32595/32595 [==============================] - 28s 862us/step - loss: 3.8326e-05\n",
      "Epoch 55/100\n",
      "32595/32595 [==============================] - 29s 878us/step - loss: 3.8446e-05\n",
      "Epoch 56/100\n",
      "32595/32595 [==============================] - 28s 860us/step - loss: 3.7998e-05\n",
      "Epoch 57/100\n",
      "32595/32595 [==============================] - 28s 858us/step - loss: 3.7990e-05\n",
      "Epoch 58/100\n",
      "32595/32595 [==============================] - 28s 861us/step - loss: 3.7683e-05\n",
      "Epoch 59/100\n",
      "32595/32595 [==============================] - 28s 861us/step - loss: 3.7663e-05\n",
      "Epoch 60/100\n",
      "32595/32595 [==============================] - 28s 858us/step - loss: 3.7715e-05\n",
      "Epoch 61/100\n",
      "32595/32595 [==============================] - 28s 860us/step - loss: 3.7702e-05\n",
      "Epoch 62/100\n",
      "32595/32595 [==============================] - 28s 851us/step - loss: 3.7622e-05\n",
      "Epoch 63/100\n",
      "32595/32595 [==============================] - 28s 865us/step - loss: 3.7405e-05\n",
      "Epoch 64/100\n",
      "32595/32595 [==============================] - 28s 860us/step - loss: 3.7614e-05\n",
      "Epoch 65/100\n",
      "32595/32595 [==============================] - 28s 865us/step - loss: 3.7388e-05\n",
      "Epoch 66/100\n",
      "32595/32595 [==============================] - 28s 867us/step - loss: 3.7432e-05\n",
      "Epoch 67/100\n",
      "32595/32595 [==============================] - 28s 863us/step - loss: 3.7600e-05\n",
      "Epoch 68/100\n",
      "32595/32595 [==============================] - 28s 854us/step - loss: 3.7520e-05\n",
      "Epoch 69/100\n",
      "32595/32595 [==============================] - 28s 858us/step - loss: 3.7652e-05\n",
      "Epoch 70/100\n",
      "32595/32595 [==============================] - 28s 856us/step - loss: 3.7506e-05\n",
      "Epoch 71/100\n",
      "32595/32595 [==============================] - 28s 852us/step - loss: 3.7608e-05\n",
      "Epoch 72/100\n",
      "32595/32595 [==============================] - 28s 850us/step - loss: 3.7284e-05\n",
      "Epoch 73/100\n",
      "32595/32595 [==============================] - 28s 859us/step - loss: 3.7254e-05\n",
      "Epoch 74/100\n",
      "32595/32595 [==============================] - 29s 883us/step - loss: 3.7288e-05\n",
      "Epoch 75/100\n",
      "32595/32595 [==============================] - 28s 863us/step - loss: 3.7546e-05\n",
      "Epoch 76/100\n",
      "32595/32595 [==============================] - 28s 858us/step - loss: 3.7312e-05\n",
      "Epoch 77/100\n",
      "32595/32595 [==============================] - 28s 871us/step - loss: 3.7427e-05\n",
      "Epoch 78/100\n",
      "32595/32595 [==============================] - 28s 864us/step - loss: 3.7117e-05\n",
      "Epoch 79/100\n",
      "32595/32595 [==============================] - 28s 863us/step - loss: 3.7328e-05\n",
      "Epoch 80/100\n",
      "32595/32595 [==============================] - 28s 862us/step - loss: 3.7231e-05\n",
      "Epoch 81/100\n",
      "32595/32595 [==============================] - 28s 865us/step - loss: 3.7408e-05\n",
      "Epoch 82/100\n",
      "32595/32595 [==============================] - 28s 862us/step - loss: 3.6929e-05\n",
      "Epoch 83/100\n",
      "32595/32595 [==============================] - 28s 866us/step - loss: 3.7079e-05\n",
      "Epoch 84/100\n",
      "32595/32595 [==============================] - 28s 858us/step - loss: 3.7182e-05\n",
      "Epoch 85/100\n",
      "32595/32595 [==============================] - 28s 860us/step - loss: 3.7354e-05\n",
      "Epoch 86/100\n",
      "32595/32595 [==============================] - 28s 855us/step - loss: 3.7326e-05\n",
      "Epoch 87/100\n",
      "32595/32595 [==============================] - 28s 858us/step - loss: 3.6969e-05\n",
      "Epoch 88/100\n",
      "32595/32595 [==============================] - 28s 868us/step - loss: 3.7195e-05\n",
      "Epoch 89/100\n",
      "32595/32595 [==============================] - 28s 860us/step - loss: 3.7258e-05\n",
      "Epoch 90/100\n",
      "32595/32595 [==============================] - 28s 854us/step - loss: 3.7203e-05\n",
      "Epoch 91/100\n",
      "32595/32595 [==============================] - 28s 862us/step - loss: 3.7298e-05\n",
      "Epoch 92/100\n",
      "32595/32595 [==============================] - 28s 858us/step - loss: 3.7220e-05\n",
      "Epoch 93/100\n",
      "32595/32595 [==============================] - 28s 865us/step - loss: 3.7259e-05\n",
      "Epoch 94/100\n",
      "32595/32595 [==============================] - 28s 859us/step - loss: 3.7156e-05\n",
      "Epoch 95/100\n",
      "32595/32595 [==============================] - 28s 858us/step - loss: 3.7186e-05\n",
      "Epoch 96/100\n",
      "32595/32595 [==============================] - 28s 852us/step - loss: 3.6908e-05\n",
      "Epoch 97/100\n",
      "32595/32595 [==============================] - 28s 857us/step - loss: 3.7129e-05\n",
      "Epoch 98/100\n",
      "32595/32595 [==============================] - 28s 867us/step - loss: 3.6895e-05\n",
      "Epoch 99/100\n",
      "32595/32595 [==============================] - 29s 876us/step - loss: 3.7026e-05\n",
      "Epoch 100/100\n",
      "32595/32595 [==============================] - 28s 862us/step - loss: 3.6656e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as lstm_cell_1_layer_call_fn, lstm_cell_1_layer_call_and_return_conditional_losses while saving (showing 2 of 2). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:\\Users\\Martynow\\AppData\\Local\\Temp\\tmpe53ljkqj\\model\\data\\model\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:\\Users\\Martynow\\AppData\\Local\\Temp\\tmpe53ljkqj\\model\\data\\model\\assets\n",
      "WARNING:absl:<keras.layers.recurrent.LSTMCell object at 0x0000014225388BE0> has the same name 'LSTMCell' as a built-in Keras object. Consider renaming <class 'keras.layers.recurrent.LSTMCell'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1424ad2d9d0>"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "modelLTSMScaled.fit(trainX, trainY, epochs=100, batch_size=1, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Score: 0.00 MSE (0.01 RMSE)\n",
      "Test Score: 0.00 MSE (0.01 RMSE)\n"
     ]
    }
   ],
   "source": [
    "trainScore = modelLTSMScaled.evaluate(xTRain, yTrain, verbose=0)\n",
    "print('Train Score: %.2f MSE (%.2f RMSE)' % (trainScore, math.sqrt(trainScore)))\n",
    "testScore = modelLTSMScaled.evaluate(xTest, yTest, verbose=0)\n",
    "print('Test Score: %.2f MSE (%.2f RMSE)' % (testScore, math.sqrt(testScore)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "#mlflow.tensorflow.autolog(disable = True, every_n_iter=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Run(Experiment: finalSequential,\n",
      "Id: 67f14752-8d9f-4fa3-b20b-352f5b560f75,\n",
      "Type: None,\n",
      "Status: Completed)]\n"
     ]
    }
   ],
   "source": [
    "experiment_name = 'finalSequential'\n",
    "\n",
    "# gets the list of runs for your experiment as an array\n",
    "exp = ws.experiments[experiment_name]\n",
    "runs = list(exp.get_runs())\n",
    "print(runs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "67f14752-8d9f-4fa3-b20b-352f5b560f75\n"
     ]
    }
   ],
   "source": [
    "runid = runs[-1].id\n",
    "print(runid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_path = 'model'\n",
    "\n",
    "model_uri='runs:/{}/{}'.format(runid, model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#config information from model stored in azure, direct Azure to Azure pipeline\n",
    "aci_config = AciWebservice.deploy_configuration(cpu_cores=1, \n",
    "                                                memory_gb=1, \n",
    "                                                tags={'method' : 'keras'}, \n",
    "                                                description='finalsequential',\n",
    "                                                location='eastus')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Martynow\\AppData\\Local\\Temp/ipykernel_19608/572064898.py:2: DeprecationWarning: ``mlflow.azureml.deploy`` is deprecated since 1.19.0. This method will be removed in a near future release. Use ``the azureml deployment plugin, https://aka.ms/aml-mlflow-deploy`` instead.\n",
      "  (webservice,model) = mlflow.azureml.deploy( model_uri='runs:/{}/{}'.format(runid, model_path),\n",
      "Successfully registered model 'finalsequentialmodel'.\n",
      "2022/05/15 13:36:46 INFO mlflow.tracking._model_registry.client: Waiting up to 300 seconds for model version to finish creation.                     Model name: finalsequentialmodel, version 1\n",
      "Created version '1' of model 'finalsequentialmodel'.\n",
      "2022/05/15 13:36:46 INFO mlflow.azureml: Registered an Azure Model with name: `finalsequentialmodel` and version: `finalsequentialmodel:1`\n",
      "2022/05/15 13:36:47 INFO mlflow.azureml: Found registered model in AzureML with ID 'finalsequentialmodel:1'\n",
      "2022/05/15 13:36:57 INFO mlflow.azureml: Deploying an Azure Webservice with name: `finasequential-model-1`\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tips: You can try get_logs(): https://aka.ms/debugimage#dockerlog or local deployment: https://aka.ms/debugimage#debug-locally to debug if deployment takes longer than 10 minutes.\n",
      "Running\n",
      "2022-05-15 13:36:51-05:00 Creating Container Registry if not exists.\n",
      "2022-05-15 13:36:52-05:00 Registering the environment.\n",
      "2022-05-15 13:36:53-05:00 Building image..\n",
      "2022-05-15 13:42:50-05:00 Generating deployment configuration.\n",
      "2022-05-15 13:42:51-05:00 Submitting deployment to compute..\n",
      "2022-05-15 13:42:55-05:00 Checking the status of deployment finasequential-model-1..\n",
      "2022-05-15 13:46:10-05:00 Checking the status of inference endpoint finasequential-model-1.\n",
      "Succeeded\n",
      "ACI service creation operation finished, operation \"Succeeded\"\n",
      "Tips: You can try get_logs(): https://aka.ms/debugimage#dockerlog or local deployment: https://aka.ms/debugimage#debug-locally to debug if deployment takes longer than 10 minutes.\n",
      "SucceededACI service creation operation finished, operation \"Succeeded\"\n"
     ]
    }
   ],
   "source": [
    "#deploying the model\n",
    "(webservice,model) = mlflow.azureml.deploy( model_uri='runs:/{}/{}'.format(runid, model_path),\n",
    "                      workspace=ws,\n",
    "                      model_name='finalsequentialmodel', \n",
    "                      service_name='finasequential-model-1', \n",
    "                      deployment_config=aci_config, \n",
    "                      tags=None, mlflow_home=None, synchronous=True)\n",
    "\n",
    "webservice.wait_for_deployment(show_output=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [],
   "source": [
    "# URL for the model\n",
    "scoring_uri = 'http://6dedce89-03cb-4eec-9809-cf915d6e00c4.eastus.azurecontainer.io/score'\n",
    "\n",
    "\n",
    "# Set the content type\n",
    "#headers = {'Content-Type': 'application/json; format=pandas-split'}\n",
    "headers = {'Content-Type':'application/json'}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "startDate = '2022-03-31'\n",
    "endDate = '2022-05-01'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "#getting the price of bitcoin for the month of April. With the last day of March to help feed tomorrow dates.\n",
    "response = requests.get('https://api.coindesk.com/v1/bpi/historical/close.json?start='+startDate+'&end='+endDate )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'{\"bpi\":{\"2022-03-31\":46318.5625,\"2022-04-01\":46154.5,\"2022-04-02\":46321.275,\"2022-04-03\":46571.355,\"2022-04-04\":45701.5475,\"2022-04-05\":45809.58,\"2022-04-06\":44106.255,\"2022-04-07\":43600,\"2022-04-08\":43090.215,\"2022-04-09\":42459.5,\"2022-04-10\":42726,\"2022-04-11\":40865.25,\"2022-04-12\":40617.5,\"2022-04-13\":39888.5,\"2022-04-14\":41023.5,\"2022-04-15\":40310.5,\"2022-04-16\":40411.5,\"2022-04-17\":40339.5,\"2022-04-18\":39036.355,\"2022-04-19\":40661.67,\"2022-04-20\":41440,\"2022-04-21\":41931,\"2022-04-22\":39494.5,\"2022-04-23\":39732.605,\"2022-04-24\":39605.645,\"2022-04-25\":39111.5,\"2022-04-26\":39971.98,\"2022-04-27\":39043.5,\"2022-04-28\":39627.555,\"2022-04-29\":39158.385,\"2022-04-30\":38617,\"2022-05-01\":37923.8125},\"disclaimer\":\"This data was produced from the CoinDesk Bitcoin Price Index. BPI value data returned as USD.\",\"time\":{\"updated\":\"May 2, 2022 00:03:00 UTC\",\"updatedISO\":\"2022-05-02T00:03:00+00:00\"}}'"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response.text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "btcPrices = response.json()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "aprilDF = pd.DataFrame().from_dict(btcPrices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>bpi</th>\n",
       "      <th>disclaimer</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2022-03-31</th>\n",
       "      <td>46318.5625</td>\n",
       "      <td>This data was produced from the CoinDesk Bitco...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-04-01</th>\n",
       "      <td>46154.5000</td>\n",
       "      <td>This data was produced from the CoinDesk Bitco...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-04-02</th>\n",
       "      <td>46321.2750</td>\n",
       "      <td>This data was produced from the CoinDesk Bitco...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-04-03</th>\n",
       "      <td>46571.3550</td>\n",
       "      <td>This data was produced from the CoinDesk Bitco...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-04-04</th>\n",
       "      <td>45701.5475</td>\n",
       "      <td>This data was produced from the CoinDesk Bitco...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   bpi                                         disclaimer time\n",
       "2022-03-31  46318.5625  This data was produced from the CoinDesk Bitco...  NaN\n",
       "2022-04-01  46154.5000  This data was produced from the CoinDesk Bitco...  NaN\n",
       "2022-04-02  46321.2750  This data was produced from the CoinDesk Bitco...  NaN\n",
       "2022-04-03  46571.3550  This data was produced from the CoinDesk Bitco...  NaN\n",
       "2022-04-04  45701.5475  This data was produced from the CoinDesk Bitco...  NaN"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "aprilDF.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "aprilDF = aprilDF.drop([\"disclaimer\", \"time\"], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>bpi</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2022-03-31</th>\n",
       "      <td>46318.5625</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-04-01</th>\n",
       "      <td>46154.5000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-04-02</th>\n",
       "      <td>46321.2750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-04-03</th>\n",
       "      <td>46571.3550</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-04-04</th>\n",
       "      <td>45701.5475</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   bpi\n",
       "2022-03-31  46318.5625\n",
       "2022-04-01  46154.5000\n",
       "2022-04-02  46321.2750\n",
       "2022-04-03  46571.3550\n",
       "2022-04-04  45701.5475"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "aprilDF.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "aprilDF[\"tomorrowOpen\"] = aprilDF[\"bpi\"].shift(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>bpi</th>\n",
       "      <th>tomorrowOpen</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2022-03-31</th>\n",
       "      <td>46318.5625</td>\n",
       "      <td>46154.5000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-04-01</th>\n",
       "      <td>46154.5000</td>\n",
       "      <td>46321.2750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-04-02</th>\n",
       "      <td>46321.2750</td>\n",
       "      <td>46571.3550</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-04-03</th>\n",
       "      <td>46571.3550</td>\n",
       "      <td>45701.5475</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-04-04</th>\n",
       "      <td>45701.5475</td>\n",
       "      <td>45809.5800</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   bpi  tomorrowOpen\n",
       "2022-03-31  46318.5625    46154.5000\n",
       "2022-04-01  46154.5000    46321.2750\n",
       "2022-04-02  46321.2750    46571.3550\n",
       "2022-04-03  46571.3550    45701.5475\n",
       "2022-04-04  45701.5475    45809.5800"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "aprilDF.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>bpi</th>\n",
       "      <th>tomorrowOpen</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2022-04-29</th>\n",
       "      <td>39158.3850</td>\n",
       "      <td>38617.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-04-30</th>\n",
       "      <td>38617.0000</td>\n",
       "      <td>37923.8125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-05-01</th>\n",
       "      <td>37923.8125</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>updated</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>updatedISO</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   bpi  tomorrowOpen\n",
       "2022-04-29  39158.3850    38617.0000\n",
       "2022-04-30  38617.0000    37923.8125\n",
       "2022-05-01  37923.8125           NaN\n",
       "updated            NaN           NaN\n",
       "updatedISO         NaN           NaN"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "aprilDF.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "aprilDF = aprilDF.dropna(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'{\"name\":\"2022-03-31\",\"index\":[\"bpi\",\"tomorrowOpen\"],\"data\":[46318.5625,46154.5]}'"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "aprilDF.iloc[0].to_json(orient='split')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'{\"name\":\"bpi\",\"index\":[\"2022-03-31\",\"2022-04-01\",\"2022-04-02\",\"2022-04-03\",\"2022-04-04\",\"2022-04-05\",\"2022-04-06\",\"2022-04-07\",\"2022-04-08\",\"2022-04-09\",\"2022-04-10\",\"2022-04-11\",\"2022-04-12\",\"2022-04-13\",\"2022-04-14\",\"2022-04-15\",\"2022-04-16\",\"2022-04-17\",\"2022-04-18\",\"2022-04-19\",\"2022-04-20\",\"2022-04-21\",\"2022-04-22\",\"2022-04-23\",\"2022-04-24\",\"2022-04-25\",\"2022-04-26\",\"2022-04-27\",\"2022-04-28\",\"2022-04-29\",\"2022-04-30\"],\"data\":[46318.5625,46154.5,46321.275,46571.355,45701.5475,45809.58,44106.255,43600.0,43090.215,42459.5,42726.0,40865.25,40617.5,39888.5,41023.5,40310.5,40411.5,40339.5,39036.355,40661.67,41440.0,41931.0,39494.5,39732.605,39605.645,39111.5,39971.98,39043.5,39627.555,39158.385,38617.0]}'"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "aprilDF[\"bpi\"].to_json(orient='split')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[46318.5625,\n",
       " 46154.5,\n",
       " 46321.275,\n",
       " 46571.355,\n",
       " 45701.5475,\n",
       " 45809.58,\n",
       " 44106.255,\n",
       " 43600.0,\n",
       " 43090.215,\n",
       " 42459.5,\n",
       " 42726.0,\n",
       " 40865.25,\n",
       " 40617.5,\n",
       " 39888.5,\n",
       " 41023.5,\n",
       " 40310.5,\n",
       " 40411.5,\n",
       " 40339.5,\n",
       " 39036.355,\n",
       " 40661.67,\n",
       " 41440.0,\n",
       " 41931.0,\n",
       " 39494.5,\n",
       " 39732.605,\n",
       " 39605.645,\n",
       " 39111.5,\n",
       " 39971.98,\n",
       " 39043.5,\n",
       " 39627.555,\n",
       " 39158.385,\n",
       " 38617.0]"
      ]
     },
     "execution_count": 205,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    " aprilDF[\"bpi\"].to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_data = {\"data\":  aprilDF[\"bpi\"].to_list()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'data': [46318.5625,\n",
       "  46154.5,\n",
       "  46321.275,\n",
       "  46571.355,\n",
       "  45701.5475,\n",
       "  45809.58,\n",
       "  44106.255,\n",
       "  43600.0,\n",
       "  43090.215,\n",
       "  42459.5,\n",
       "  42726.0,\n",
       "  40865.25,\n",
       "  40617.5,\n",
       "  39888.5,\n",
       "  41023.5,\n",
       "  40310.5,\n",
       "  40411.5,\n",
       "  40339.5,\n",
       "  39036.355,\n",
       "  40661.67,\n",
       "  41440.0,\n",
       "  41931.0,\n",
       "  39494.5,\n",
       "  39732.605,\n",
       "  39605.645,\n",
       "  39111.5,\n",
       "  39971.98,\n",
       "  39043.5,\n",
       "  39627.555,\n",
       "  39158.385,\n",
       "  38617.0]}"
      ]
     },
     "execution_count": 210,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict"
      ]
     },
     "execution_count": 211,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(input_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_data= str.encode(json.dumps(input_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "b'{\"data\": [46318.5625, 46154.5, 46321.275, 46571.355, 45701.5475, 45809.58, 44106.255, 43600.0, 43090.215, 42459.5, 42726.0, 40865.25, 40617.5, 39888.5, 41023.5, 40310.5, 40411.5, 40339.5, 39036.355, 40661.67, 41440.0, 41931.0, 39494.5, 39732.605, 39605.645, 39111.5, 39971.98, 39043.5, 39627.555, 39158.385, 38617.0]}'"
      ]
     },
     "execution_count": 213,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Failed to parse input as a Pandas DataFrame. Ensure that the input is a valid JSON-formatted Pandas DataFrame with the `split` orient produced using the `pandas.DataFrame.to_json(..., orient='split')` method.\n"
     ]
    }
   ],
   "source": [
    "resp = requests.get(scoring_uri, input_data, headers=headers)\n",
    "print(resp.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "b'[{\"0\": 46387.5546875}, {\"0\": 46223.2578125}, {\"0\": 46390.26953125}, {\"0\": 46640.70703125}, {\"0\": 45769.66015625}, {\"0\": 45877.84375}, {\"0\": 44172.09765625}, {\"0\": 43665.12109375}, {\"0\": 43154.609375}, {\"0\": 42522.99609375}, {\"0\": 42789.87890625}, {\"0\": 40926.4765625}, {\"0\": 40678.375}, {\"0\": 39948.33984375}, {\"0\": 41084.953125}, {\"0\": 40370.94140625}, {\"0\": 40472.08203125}, {\"0\": 40399.9765625}, {\"0\": 39094.98046875}, {\"0\": 40722.609375}, {\"0\": 41502.046875}, {\"0\": 41993.7421875}, {\"0\": 39553.77734375}, {\"0\": 39792.22265625}, {\"0\": 39665.078125}, {\"0\": 39170.23046875}, {\"0\": 40031.9375}, {\"0\": 39102.1328125}, {\"0\": 39687.01953125}, {\"0\": 39217.18359375}, {\"0\": 38675.0234375}]'\n"
     ]
    }
   ],
   "source": [
    "#taken from the azure code ingestion component\n",
    "\n",
    "def allowSelfSignedHttps(allowed):\n",
    "    # bypass the server certificate verification on client side\n",
    "    if allowed and not os.environ.get('PYTHONHTTPSVERIFY', '') and getattr(ssl, '_create_unverified_context', None):\n",
    "        ssl._create_default_https_context = ssl._create_unverified_context\n",
    "\n",
    "allowSelfSignedHttps(True) # this line is needed if you use self-signed certificate in your scoring service.\n",
    "\n",
    "req = urllib.request.Request(url, input_data, headers)\n",
    "\n",
    "try:\n",
    "    response = urllib.request.urlopen(req)\n",
    "\n",
    "    result = response.read()\n",
    "    print(result)\n",
    "except urllib.error.HTTPError as error:\n",
    "    print(\"The request failed with status code: \" + str(error.code))\n",
    "\n",
    "    # Print the headers - they include the requert ID and the timestamp, which are useful for debugging the failure\n",
    "    print(error.info())\n",
    "    print(error.read().decode(\"utf8\", 'ignore'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "b'[{\"0\": 46387.5546875}, {\"0\": 46223.2578125}, {\"0\": 46390.26953125}, {\"0\": 46640.70703125}, {\"0\": 45769.66015625}, {\"0\": 45877.84375}, {\"0\": 44172.09765625}, {\"0\": 43665.12109375}, {\"0\": 43154.609375}, {\"0\": 42522.99609375}, {\"0\": 42789.87890625}, {\"0\": 40926.4765625}, {\"0\": 40678.375}, {\"0\": 39948.33984375}, {\"0\": 41084.953125}, {\"0\": 40370.94140625}, {\"0\": 40472.08203125}, {\"0\": 40399.9765625}, {\"0\": 39094.98046875}, {\"0\": 40722.609375}, {\"0\": 41502.046875}, {\"0\": 41993.7421875}, {\"0\": 39553.77734375}, {\"0\": 39792.22265625}, {\"0\": 39665.078125}, {\"0\": 39170.23046875}, {\"0\": 40031.9375}, {\"0\": 39102.1328125}, {\"0\": 39687.01953125}, {\"0\": 39217.18359375}, {\"0\": 38675.0234375}]'"
      ]
     },
     "execution_count": 216,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
